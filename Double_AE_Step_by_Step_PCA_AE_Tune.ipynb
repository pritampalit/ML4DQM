{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "Double_AE_Step-by-Step_PCA_AE_Tune.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pritampalit/ML4DQM/blob/master/Double_AE_Step_by_Step_PCA_AE_Tune.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SE49EHPK4zIL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "148bb8f9-b2b7-4f84-a06b-1c9a52214d04"
      },
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvMT6I6BHHN2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "bd8607be-1949-4d02-aab1-22c23e0589f6"
      },
      "source": [
        "import pandas as pd\n",
        "#from google.colab import files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from ast import literal_eval\n",
        "import json\n",
        "#%matplotlib inline\n",
        "\n",
        "\n",
        "#uploaded = files.upload()\n",
        "#import io \n",
        "#df= pd.read_csv(io.BytesIO(uploaded['Tot_ZeroBias_UL2017_DataFrame_chargeInner_PXLayer_1.csv']))\n",
        "#df= pd.read_csv('ZeroBias_2017UL_DataFrame_ChargeInnerLayer4.txt')\n",
        "df= pd.read_csv('/content/drive/My Drive/Colab Notebooks/Tot_ZeroBias_UL2017_DataFrame_chargeInner_PXLayer_1.csv')\n",
        "df['histo']=df['histo'].apply(literal_eval)\n",
        "\n",
        "df.set_index(['fromrun','fromlumi'], inplace=True, drop=False)\n",
        "df.sort_index(inplace=True)\n",
        "print(df['histo'].shape)\n",
        "print(df.tail())\n",
        "print(df.shape)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "(225954,)\n",
            "                  Unnamed: 0  ...                                              histo\n",
            "fromrun fromlumi              ...                                                   \n",
            "306462  95             67823  ...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
            "        96             67824  ...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
            "        97             67825  ...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
            "        98             67826  ...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
            "        99             67827  ...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
            "\n",
            "[5 rows x 10 columns]\n",
            "(225954, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwqbcqC86TL2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
        "from keras import regularizers\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_curve\n",
        "from sklearn.metrics import recall_score, classification_report, auc, roc_curve\n",
        "from sklearn.metrics import precision_recall_fscore_support, f1_score\n",
        "from numpy.random import seed\n",
        "seed(1)\n",
        "import tensorflow\n",
        "#from tensorflow import set_random_seed\n",
        "tensorflow.random.set_seed(2)\n",
        "#set_random_seed(2)\n",
        "SEED = 123 #used to help randomly select the data points\n",
        "DATA_SPLIT_PCT = 0.2\n",
        "DATA_SPLIT_PCT_VALID = 0.1\n",
        "rcParams['figure.figsize'] = 10, 8\n",
        "\n",
        "\n"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IF45uVsH846x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 837
        },
        "outputId": "aac73883-0fcf-477b-fc8f-c02dc77b4bac"
      },
      "source": [
        "#add Golden JSON labels to the DF\n",
        "import json\n",
        "\n",
        "def checkLS(run,ls):\n",
        "    isok=False\n",
        "    global jsondata\n",
        "\n",
        "    if str(run) in jsondata.keys():\n",
        "        for i in jsondata[str(run)]:\n",
        "            if (ls>=i[0] and ls <=i[1]):\n",
        "                isok=True\n",
        "                return isok\n",
        "        return   isok\n",
        "\n",
        "#load the golden json file\n",
        "jsondata={}\n",
        "with open('/content/drive/My Drive/Colab Notebooks/GoldenJSON17.json') as json_file:\n",
        "    jsondata = json.load(json_file)\n",
        "\n",
        "df['labels']=False #initialize to false\n",
        "\n",
        "for run in df['fromrun'].unique():\n",
        "    for ls in df['fromlumi'][run]:\n",
        "        df['labels'][run][ls]=checkLS(run,ls)\n",
        "\n",
        "'''\n",
        "def checkLSAnomaly(run,ls):\n",
        "    isok_anomaly=True\n",
        "    global jsondata\n",
        "    \n",
        "    if str(run) in jsondata.keys():\n",
        "        for i in jsondata[str(run)]:\n",
        "            if (ls>=i[0] and ls <=i[1]):\n",
        "                isok_anomaly=False\n",
        "                return isok_anomaly\n",
        "        return isok_anomaly\n",
        "\n",
        "\n",
        "df['anomaly']=True #initialize\n",
        "for run in df['fromrun'].unique():\n",
        "    for ls in df['fromlumi'][run]:  \n",
        "        df['anomaly'][run][ls]=checkLSAnomaly(run,ls)\n",
        "'''\n",
        "#fname_bad = 'BAD_Tot_ZeroBias_UL2017_DataFrame_chargeInner_PXLayer_1.txt'\n",
        "#fname_gold = 'GOLDEN_Tot_ZeroBias_UL2017_DataFrame_chargeInner_PXLayer_1.csv'\n",
        "#df[df['labels']!=True].to_csv(fname_bad)\n",
        "#df[df['labels']==True].to_csv(fname_gold)\n",
        "\n",
        "#print(df[df['labels']!=True]) #to check against the Golden JSON\n",
        "print(df[df['labels']==False].shape)\n",
        "print(df[df['labels']==True].shape)\n",
        "#print(df[df['anomaly']==True].shape)\n",
        "#print(df[df['anomaly']==False].shape)\n",
        "#print(df[df['anomaly']==False])\n",
        "#print(df[df['anomaly']==True])\n",
        "#print(df.shape)\n",
        "#print(df['labels'])\n",
        "#print(df['anomaly'])\n",
        "\n",
        "df['type']=df['labels']\n",
        "df['type']=df['type'].apply(lambda x:0 if x== True else 1)\n",
        "df[df['type']==0]\n"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(23655, 11)\n",
            "(202299, 11)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>fromrun</th>\n",
              "      <th>fromlumi</th>\n",
              "      <th>hname</th>\n",
              "      <th>entries</th>\n",
              "      <th>Xmax</th>\n",
              "      <th>Xmin</th>\n",
              "      <th>Xbins</th>\n",
              "      <th>metype</th>\n",
              "      <th>histo</th>\n",
              "      <th>labels</th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fromrun</th>\n",
              "      <th>fromlumi</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">297050</th>\n",
              "      <th>12</th>\n",
              "      <td>4535</td>\n",
              "      <td>297050</td>\n",
              "      <td>12</td>\n",
              "      <td>chargeInner_PXLayer_1</td>\n",
              "      <td>171304</td>\n",
              "      <td>80000.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100</td>\n",
              "      <td>3</td>\n",
              "      <td>[33, 213, 426, 548, 671, 772, 803, 796, 870, 8...</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>4536</td>\n",
              "      <td>297050</td>\n",
              "      <td>13</td>\n",
              "      <td>chargeInner_PXLayer_1</td>\n",
              "      <td>163665</td>\n",
              "      <td>80000.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100</td>\n",
              "      <td>3</td>\n",
              "      <td>[43, 201, 389, 532, 623, 664, 740, 792, 778, 7...</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>15690</td>\n",
              "      <td>297050</td>\n",
              "      <td>14</td>\n",
              "      <td>chargeInner_PXLayer_1</td>\n",
              "      <td>158787</td>\n",
              "      <td>80000.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100</td>\n",
              "      <td>3</td>\n",
              "      <td>[34, 241, 362, 501, 586, 685, 726, 682, 751, 7...</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>15691</td>\n",
              "      <td>297050</td>\n",
              "      <td>15</td>\n",
              "      <td>chargeInner_PXLayer_1</td>\n",
              "      <td>166202</td>\n",
              "      <td>80000.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100</td>\n",
              "      <td>3</td>\n",
              "      <td>[27, 226, 384, 540, 662, 717, 773, 816, 780, 7...</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>4537</td>\n",
              "      <td>297050</td>\n",
              "      <td>16</td>\n",
              "      <td>chargeInner_PXLayer_1</td>\n",
              "      <td>166349</td>\n",
              "      <td>80000.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100</td>\n",
              "      <td>3</td>\n",
              "      <td>[36, 226, 445, 471, 593, 695, 757, 801, 808, 8...</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">306460</th>\n",
              "      <th>60</th>\n",
              "      <td>62547</td>\n",
              "      <td>306460</td>\n",
              "      <td>60</td>\n",
              "      <td>chargeInner_PXLayer_1</td>\n",
              "      <td>10164</td>\n",
              "      <td>80000.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100</td>\n",
              "      <td>3</td>\n",
              "      <td>[11, 51, 59, 78, 122, 138, 181, 248, 266, 324,...</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>62548</td>\n",
              "      <td>306460</td>\n",
              "      <td>61</td>\n",
              "      <td>chargeInner_PXLayer_1</td>\n",
              "      <td>10358</td>\n",
              "      <td>80000.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100</td>\n",
              "      <td>3</td>\n",
              "      <td>[6, 40, 58, 114, 105, 162, 183, 233, 293, 336,...</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>62549</td>\n",
              "      <td>306460</td>\n",
              "      <td>62</td>\n",
              "      <td>chargeInner_PXLayer_1</td>\n",
              "      <td>10107</td>\n",
              "      <td>80000.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100</td>\n",
              "      <td>3</td>\n",
              "      <td>[11, 43, 74, 88, 99, 143, 204, 220, 254, 357, ...</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>62550</td>\n",
              "      <td>306460</td>\n",
              "      <td>63</td>\n",
              "      <td>chargeInner_PXLayer_1</td>\n",
              "      <td>10151</td>\n",
              "      <td>80000.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100</td>\n",
              "      <td>3</td>\n",
              "      <td>[6, 47, 62, 90, 116, 130, 168, 263, 288, 338, ...</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>62551</td>\n",
              "      <td>306460</td>\n",
              "      <td>64</td>\n",
              "      <td>chargeInner_PXLayer_1</td>\n",
              "      <td>327</td>\n",
              "      <td>80000.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100</td>\n",
              "      <td>3</td>\n",
              "      <td>[0, 2, 1, 3, 5, 6, 3, 8, 12, 9, 16, 12, 11, 12...</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>202299 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                  Unnamed: 0  fromrun  ...  labels type\n",
              "fromrun fromlumi                       ...             \n",
              "297050  12              4535   297050  ...    True    0\n",
              "        13              4536   297050  ...    True    0\n",
              "        14             15690   297050  ...    True    0\n",
              "        15             15691   297050  ...    True    0\n",
              "        16              4537   297050  ...    True    0\n",
              "...                      ...      ...  ...     ...  ...\n",
              "306460  60             62547   306460  ...    True    0\n",
              "        61             62548   306460  ...    True    0\n",
              "        62             62549   306460  ...    True    0\n",
              "        63             62550   306460  ...    True    0\n",
              "        64             62551   306460  ...    True    0\n",
              "\n",
              "[202299 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLedH8KoP1Xw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train, df_test = train_test_split(df, test_size=DATA_SPLIT_PCT, random_state=SEED)\n",
        "df_train, df_valid = train_test_split(df_train, test_size=DATA_SPLIT_PCT_VALID, random_state=SEED)\n",
        "\n",
        "X_train_true = np.stack(df_train['histo'][df_train['labels']==True].values, axis=0)\n",
        "X_train_false = np.stack(df_train['histo'][df_train['labels']==False].values, axis=0)\n",
        "\n",
        "X_valid_true = np.stack(df_valid['histo'][df_valid['labels']==True].values, axis=0)\n",
        "X_valid_false = np.stack(df_valid['histo'][df_valid['labels']==False].values, axis=0)\n",
        "\n",
        "\n",
        "X_test_true = np.stack(df_test['histo'][df_test['labels']==True].values, axis=0)\n",
        "X_test_false = np.stack(df_test['histo'][df_test['labels']==False].values, axis=0)\n",
        "\n",
        "from sklearn.preprocessing import normalize\n",
        "\n",
        "X_train_true_norm=normalize(X_train_true, norm='l1', axis=1) #normalise the sample, i.e the rows\n",
        "X_train_false_norm=normalize(X_train_false, norm='l1', axis=1)\n",
        "\n",
        "X_valid_true_norm=normalize(X_valid_true, norm='l1', axis=1) #normalise the sample, i.e the rows\n",
        "X_valid_false_norm=normalize(X_valid_false, norm='l1', axis=1)\n",
        "\n",
        "X_test_true_norm=normalize(X_test_true, norm='l1', axis=1) #normalise the sample, i.e the rows\n",
        "X_test_false_norm=normalize(X_test_false, norm='l1', axis=1)\n",
        "\n",
        "\n"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfHAmDd_gcm7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dd21bbe7-674d-49eb-e6c9-97b902613f2f"
      },
      "source": [
        "#build the model\n",
        "import math\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from keras.layers import Input, Dense, Layer, InputSpec\n",
        "from keras.layers.advanced_activations import PReLU\n",
        "from keras.models import Model, load_model\n",
        "from keras import backend as K\n",
        "from sklearn import decomposition\n",
        "import scipy\n",
        "import tensorflow as tf\n",
        "from keras.constraints import UnitNorm, Constraint\n",
        "from keras import regularizers, activations, initializers, constraints, Sequential\n",
        "\n",
        "def mseTop10(y_true, y_pred):\n",
        "    top_values, _ = tf.nn.top_k(K.square(y_pred - y_true), k=10, sorted=True)\n",
        "    mean=K.mean(top_values, axis=-1)\n",
        "    return mean\n",
        "\n",
        "nb_epoch = 100\n",
        "batch_size = 1000\n",
        "input_dim = X_train_true_norm.shape[1] #num of predictor variables, \n",
        "encoding_dim = 3\n",
        "#hidden_dim = int(encoding_dim / 2)\n",
        "hidden_dim = 3\n",
        "learning_rate = 1e-3\n",
        "\n",
        "input_layer = Input(shape=(input_dim, ))\n",
        "encoder = Dense(encoding_dim, activation=\"tanh\", input_shape=(input_dim,), use_bias = True)  #, activity_regularizer=regularizers.l1(learning_rate))(input_layer)\n",
        "#encoder = Dense(hidden_dim, activation=\"tanh\")(encoder)\n",
        "#decoder = Dense(hidden_dim, activation=\"tanh\" )(encoder)\n",
        "#decoder = DenseTied(encoding_dim, activation=\"tanh\", tied_to=encoder, use_bias = True)(decoder)\n",
        "decoder = Dense(input_dim, activation=\"tanh\", use_bias = True)\n",
        "autoencoder = Sequential()\n",
        "autoencoder.add(encoder)\n",
        "autoencoder.add(decoder)\n",
        "#autoencoder = Model(inputs=input_layer, outputs=decoder)\n",
        "'''\n",
        "autoencoder.compile(metrics=['accuracy'],\n",
        "                    loss='mean_squared_error',\n",
        "                    optimizer='adam')\n",
        "'''\n",
        "\n",
        "autoencoder.summary()\n",
        "autoencoder.compile(metrics=['accuracy'],\n",
        "                    loss=mseTop10,\n",
        "                    optimizer='adam')\n",
        "history = autoencoder.fit(X_train_true_norm, X_train_true_norm,\n",
        "                    epochs=nb_epoch,\n",
        "                    batch_size=batch_size,\n",
        "                    shuffle=True,\n",
        "                    validation_data=(X_valid_true_norm, X_valid_true_norm),\n",
        "                    verbose=1).history\n",
        "\n",
        "\n",
        "# Fit PCA\n",
        "pca = decomposition.PCA(n_components=3)\n",
        "pca.fit(X_train_true_norm)\n",
        "\n"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_12 (Dense)             (None, 3)                 303       \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 100)               400       \n",
            "=================================================================\n",
            "Total params: 703\n",
            "Trainable params: 703\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 145591 samples, validate on 16212 samples\n",
            "Epoch 1/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 3.0121e-04 - accuracy: 0.1699 - val_loss: 8.2446e-05 - val_accuracy: 0.1950\n",
            "Epoch 2/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 3.9325e-05 - accuracy: 0.2455 - val_loss: 2.0977e-05 - val_accuracy: 0.3282\n",
            "Epoch 3/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 1.7201e-05 - accuracy: 0.3432 - val_loss: 1.2850e-05 - val_accuracy: 0.3570\n",
            "Epoch 4/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 1.0026e-05 - accuracy: 0.3778 - val_loss: 7.1232e-06 - val_accuracy: 0.3917\n",
            "Epoch 5/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 6.0641e-06 - accuracy: 0.4038 - val_loss: 4.8449e-06 - val_accuracy: 0.4122\n",
            "Epoch 6/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 4.8281e-06 - accuracy: 0.4177 - val_loss: 4.3073e-06 - val_accuracy: 0.4165\n",
            "Epoch 7/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 4.3717e-06 - accuracy: 0.4130 - val_loss: 3.9271e-06 - val_accuracy: 0.4106\n",
            "Epoch 8/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 3.9726e-06 - accuracy: 0.4077 - val_loss: 3.5722e-06 - val_accuracy: 0.4005\n",
            "Epoch 9/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 3.6506e-06 - accuracy: 0.4029 - val_loss: 3.2977e-06 - val_accuracy: 0.3966\n",
            "Epoch 10/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 3.4219e-06 - accuracy: 0.4026 - val_loss: 3.0959e-06 - val_accuracy: 0.3997\n",
            "Epoch 11/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 3.2180e-06 - accuracy: 0.4042 - val_loss: 2.9449e-06 - val_accuracy: 0.4005\n",
            "Epoch 12/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 3.0704e-06 - accuracy: 0.4069 - val_loss: 2.8166e-06 - val_accuracy: 0.4054\n",
            "Epoch 13/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.9476e-06 - accuracy: 0.4083 - val_loss: 2.7055e-06 - val_accuracy: 0.4048\n",
            "Epoch 14/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.8391e-06 - accuracy: 0.4112 - val_loss: 2.6141e-06 - val_accuracy: 0.4093\n",
            "Epoch 15/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.7391e-06 - accuracy: 0.4152 - val_loss: 2.5255e-06 - val_accuracy: 0.4138\n",
            "Epoch 16/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.6539e-06 - accuracy: 0.4175 - val_loss: 2.4693e-06 - val_accuracy: 0.4135\n",
            "Epoch 17/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.5806e-06 - accuracy: 0.4197 - val_loss: 2.3932e-06 - val_accuracy: 0.4195\n",
            "Epoch 18/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.5237e-06 - accuracy: 0.4227 - val_loss: 2.3286e-06 - val_accuracy: 0.4213\n",
            "Epoch 19/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.4662e-06 - accuracy: 0.4256 - val_loss: 2.2874e-06 - val_accuracy: 0.4225\n",
            "Epoch 20/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.4142e-06 - accuracy: 0.4290 - val_loss: 2.2417e-06 - val_accuracy: 0.4263\n",
            "Epoch 21/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.3692e-06 - accuracy: 0.4303 - val_loss: 2.2053e-06 - val_accuracy: 0.4311\n",
            "Epoch 22/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.3400e-06 - accuracy: 0.4335 - val_loss: 2.1720e-06 - val_accuracy: 0.4327\n",
            "Epoch 23/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.2945e-06 - accuracy: 0.4356 - val_loss: 2.1499e-06 - val_accuracy: 0.4303\n",
            "Epoch 24/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.2702e-06 - accuracy: 0.4368 - val_loss: 2.1310e-06 - val_accuracy: 0.4359\n",
            "Epoch 25/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.2435e-06 - accuracy: 0.4400 - val_loss: 2.1030e-06 - val_accuracy: 0.4362\n",
            "Epoch 26/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.2247e-06 - accuracy: 0.4423 - val_loss: 2.0841e-06 - val_accuracy: 0.4405\n",
            "Epoch 27/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.2057e-06 - accuracy: 0.4428 - val_loss: 2.0700e-06 - val_accuracy: 0.4411\n",
            "Epoch 28/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1897e-06 - accuracy: 0.4458 - val_loss: 2.0557e-06 - val_accuracy: 0.4433\n",
            "Epoch 29/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1772e-06 - accuracy: 0.4493 - val_loss: 2.0542e-06 - val_accuracy: 0.4505\n",
            "Epoch 30/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1839e-06 - accuracy: 0.4501 - val_loss: 2.0671e-06 - val_accuracy: 0.4543\n",
            "Epoch 31/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1646e-06 - accuracy: 0.4541 - val_loss: 2.0397e-06 - val_accuracy: 0.4533\n",
            "Epoch 32/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1585e-06 - accuracy: 0.4564 - val_loss: 2.0275e-06 - val_accuracy: 0.4576\n",
            "Epoch 33/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1580e-06 - accuracy: 0.4601 - val_loss: 2.0218e-06 - val_accuracy: 0.4575\n",
            "Epoch 34/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1425e-06 - accuracy: 0.4593 - val_loss: 2.0256e-06 - val_accuracy: 0.4604\n",
            "Epoch 35/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1414e-06 - accuracy: 0.4609 - val_loss: 2.0200e-06 - val_accuracy: 0.4635\n",
            "Epoch 36/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1380e-06 - accuracy: 0.4619 - val_loss: 2.0182e-06 - val_accuracy: 0.4525\n",
            "Epoch 37/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1333e-06 - accuracy: 0.4620 - val_loss: 2.0175e-06 - val_accuracy: 0.4708\n",
            "Epoch 38/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1419e-06 - accuracy: 0.4641 - val_loss: 2.0110e-06 - val_accuracy: 0.4682\n",
            "Epoch 39/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1477e-06 - accuracy: 0.4637 - val_loss: 2.0280e-06 - val_accuracy: 0.4713\n",
            "Epoch 40/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1340e-06 - accuracy: 0.4658 - val_loss: 2.0182e-06 - val_accuracy: 0.4732\n",
            "Epoch 41/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1473e-06 - accuracy: 0.4645 - val_loss: 2.0141e-06 - val_accuracy: 0.4614\n",
            "Epoch 42/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1453e-06 - accuracy: 0.4650 - val_loss: 2.0081e-06 - val_accuracy: 0.4640\n",
            "Epoch 43/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1381e-06 - accuracy: 0.4640 - val_loss: 2.0709e-06 - val_accuracy: 0.4619\n",
            "Epoch 44/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1383e-06 - accuracy: 0.4636 - val_loss: 2.0058e-06 - val_accuracy: 0.4545\n",
            "Epoch 45/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1337e-06 - accuracy: 0.4634 - val_loss: 2.0041e-06 - val_accuracy: 0.4677\n",
            "Epoch 46/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1187e-06 - accuracy: 0.4633 - val_loss: 2.0005e-06 - val_accuracy: 0.4695\n",
            "Epoch 47/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1473e-06 - accuracy: 0.4640 - val_loss: 2.0046e-06 - val_accuracy: 0.4677\n",
            "Epoch 48/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1468e-06 - accuracy: 0.4639 - val_loss: 2.0323e-06 - val_accuracy: 0.4645\n",
            "Epoch 49/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1352e-06 - accuracy: 0.4638 - val_loss: 2.0011e-06 - val_accuracy: 0.4547\n",
            "Epoch 50/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1417e-06 - accuracy: 0.4656 - val_loss: 2.0022e-06 - val_accuracy: 0.4631\n",
            "Epoch 51/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1584e-06 - accuracy: 0.4615 - val_loss: 2.0033e-06 - val_accuracy: 0.4584\n",
            "Epoch 52/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1207e-06 - accuracy: 0.4625 - val_loss: 2.0107e-06 - val_accuracy: 0.4593\n",
            "Epoch 53/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1178e-06 - accuracy: 0.4603 - val_loss: 1.9911e-06 - val_accuracy: 0.4575\n",
            "Epoch 54/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1241e-06 - accuracy: 0.4626 - val_loss: 2.0121e-06 - val_accuracy: 0.4527\n",
            "Epoch 55/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1314e-06 - accuracy: 0.4621 - val_loss: 2.0115e-06 - val_accuracy: 0.4722\n",
            "Epoch 56/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1393e-06 - accuracy: 0.4624 - val_loss: 2.0375e-06 - val_accuracy: 0.4568\n",
            "Epoch 57/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1376e-06 - accuracy: 0.4621 - val_loss: 1.9977e-06 - val_accuracy: 0.4714\n",
            "Epoch 58/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1287e-06 - accuracy: 0.4611 - val_loss: 2.0073e-06 - val_accuracy: 0.4550\n",
            "Epoch 59/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1132e-06 - accuracy: 0.4601 - val_loss: 2.0021e-06 - val_accuracy: 0.4661\n",
            "Epoch 60/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1103e-06 - accuracy: 0.4618 - val_loss: 2.0038e-06 - val_accuracy: 0.4604\n",
            "Epoch 61/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1405e-06 - accuracy: 0.4622 - val_loss: 2.0888e-06 - val_accuracy: 0.4590\n",
            "Epoch 62/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1418e-06 - accuracy: 0.4617 - val_loss: 2.0625e-06 - val_accuracy: 0.4532\n",
            "Epoch 63/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1404e-06 - accuracy: 0.4611 - val_loss: 2.0020e-06 - val_accuracy: 0.4667\n",
            "Epoch 64/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1144e-06 - accuracy: 0.4610 - val_loss: 2.0059e-06 - val_accuracy: 0.4618\n",
            "Epoch 65/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1176e-06 - accuracy: 0.4602 - val_loss: 2.0025e-06 - val_accuracy: 0.4560\n",
            "Epoch 66/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1093e-06 - accuracy: 0.4604 - val_loss: 1.9894e-06 - val_accuracy: 0.4559\n",
            "Epoch 67/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1123e-06 - accuracy: 0.4585 - val_loss: 2.0008e-06 - val_accuracy: 0.4507\n",
            "Epoch 68/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1206e-06 - accuracy: 0.4612 - val_loss: 2.0010e-06 - val_accuracy: 0.4624\n",
            "Epoch 69/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1290e-06 - accuracy: 0.4612 - val_loss: 1.9991e-06 - val_accuracy: 0.4549\n",
            "Epoch 70/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1165e-06 - accuracy: 0.4575 - val_loss: 2.0096e-06 - val_accuracy: 0.4511\n",
            "Epoch 71/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1093e-06 - accuracy: 0.4576 - val_loss: 1.9842e-06 - val_accuracy: 0.4547\n",
            "Epoch 72/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1087e-06 - accuracy: 0.4624 - val_loss: 2.0077e-06 - val_accuracy: 0.4645\n",
            "Epoch 73/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1070e-06 - accuracy: 0.4596 - val_loss: 2.0170e-06 - val_accuracy: 0.4462\n",
            "Epoch 74/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1087e-06 - accuracy: 0.4567 - val_loss: 1.9923e-06 - val_accuracy: 0.4508\n",
            "Epoch 75/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1040e-06 - accuracy: 0.4583 - val_loss: 1.9925e-06 - val_accuracy: 0.4636\n",
            "Epoch 76/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 2.1043e-06 - accuracy: 0.4591 - val_loss: 1.9919e-06 - val_accuracy: 0.4593\n",
            "Epoch 77/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 2.1054e-06 - accuracy: 0.4593 - val_loss: 2.0169e-06 - val_accuracy: 0.4381\n",
            "Epoch 78/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 2.1084e-06 - accuracy: 0.4611 - val_loss: 1.9874e-06 - val_accuracy: 0.4655\n",
            "Epoch 79/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1074e-06 - accuracy: 0.4581 - val_loss: 1.9868e-06 - val_accuracy: 0.4407\n",
            "Epoch 80/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 2.1334e-06 - accuracy: 0.4602 - val_loss: 1.9924e-06 - val_accuracy: 0.4729\n",
            "Epoch 81/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1092e-06 - accuracy: 0.4570 - val_loss: 2.0011e-06 - val_accuracy: 0.4566\n",
            "Epoch 82/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1016e-06 - accuracy: 0.4606 - val_loss: 1.9888e-06 - val_accuracy: 0.4611\n",
            "Epoch 83/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1267e-06 - accuracy: 0.4609 - val_loss: 1.9905e-06 - val_accuracy: 0.4592\n",
            "Epoch 84/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1017e-06 - accuracy: 0.4604 - val_loss: 1.9958e-06 - val_accuracy: 0.4599\n",
            "Epoch 85/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1024e-06 - accuracy: 0.4616 - val_loss: 1.9880e-06 - val_accuracy: 0.4725\n",
            "Epoch 86/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1015e-06 - accuracy: 0.4602 - val_loss: 1.9859e-06 - val_accuracy: 0.4530\n",
            "Epoch 87/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1037e-06 - accuracy: 0.4598 - val_loss: 2.0074e-06 - val_accuracy: 0.4511\n",
            "Epoch 88/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1154e-06 - accuracy: 0.4589 - val_loss: 1.9864e-06 - val_accuracy: 0.4444\n",
            "Epoch 89/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1177e-06 - accuracy: 0.4582 - val_loss: 1.9852e-06 - val_accuracy: 0.4461\n",
            "Epoch 90/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1102e-06 - accuracy: 0.4594 - val_loss: 1.9929e-06 - val_accuracy: 0.4628\n",
            "Epoch 91/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.0996e-06 - accuracy: 0.4608 - val_loss: 1.9818e-06 - val_accuracy: 0.4621\n",
            "Epoch 92/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1003e-06 - accuracy: 0.4591 - val_loss: 1.9932e-06 - val_accuracy: 0.4597\n",
            "Epoch 93/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1010e-06 - accuracy: 0.4611 - val_loss: 1.9897e-06 - val_accuracy: 0.4566\n",
            "Epoch 94/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1164e-06 - accuracy: 0.4584 - val_loss: 1.9915e-06 - val_accuracy: 0.4616\n",
            "Epoch 95/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.0996e-06 - accuracy: 0.4597 - val_loss: 1.9988e-06 - val_accuracy: 0.4580\n",
            "Epoch 96/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1104e-06 - accuracy: 0.4576 - val_loss: 1.9893e-06 - val_accuracy: 0.4583\n",
            "Epoch 97/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1018e-06 - accuracy: 0.4593 - val_loss: 1.9933e-06 - val_accuracy: 0.4693\n",
            "Epoch 98/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.0997e-06 - accuracy: 0.4594 - val_loss: 1.9921e-06 - val_accuracy: 0.4574\n",
            "Epoch 99/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1300e-06 - accuracy: 0.4601 - val_loss: 1.9907e-06 - val_accuracy: 0.4644\n",
            "Epoch 100/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1026e-06 - accuracy: 0.4608 - val_loss: 1.9814e-06 - val_accuracy: 0.4612\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PCA(copy=True, iterated_power='auto', n_components=3, random_state=None,\n",
              "    svd_solver='auto', tol=0.0, whiten=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ptrkdhun_NM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 990
        },
        "outputId": "708f457b-3f3c-43dd-b066-47a7c38f141f"
      },
      "source": [
        "#print(autoencoder.layers[0].get_weights()[0])\n",
        "w_encoder = np.round(autoencoder.layers[0].get_weights()[0], 2).T  # W in Figure 3.\n",
        "w_decoder = np.round(autoencoder.layers[1].get_weights()[0], 2)  # W' in Figure 3.\n",
        "print('Encoder weights \\n', w_encoder)\n",
        "print('Decoder weights \\n', w_decoder)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder weights \n",
            " [[ 0.12  0.03 -0.07 -0.05 -0.05 -0.01 -0.01 -0.2  -0.11 -0.12 -0.13 -0.2\n",
            "  -0.15 -0.15 -0.2  -0.16 -0.18 -0.15 -0.29 -0.08 -0.07 -0.08 -0.14 -0.05\n",
            "   0.11  0.03  0.18  0.14  0.06  0.11  0.12  0.11  0.17  0.19  0.2   0.3\n",
            "   0.21  0.22  0.13  0.03 -0.01 -0.07  0.1  -0.06  0.16  0.02  0.12  0.22\n",
            "  -0.07  0.15  0.14 -0.09  0.02 -0.09  0.07  0.15  0.18  0.13 -0.03  0.11\n",
            "  -0.09  0.18  0.04  0.01 -0.03  0.16  0.03  0.22  0.25  0.1  -0.09  0.11\n",
            "   0.16  0.05  0.28  0.07  0.27  0.02  0.24 -0.08 -0.03 -0.13 -0.16 -0.13\n",
            "   0.26 -0.04 -0.08  0.15 -0.17  0.14  0.19  0.01 -0.01  0.13  0.2  -0.21\n",
            "  -0.04 -0.08  0.12  0.21]\n",
            " [-0.19 -0.33 -0.16 -0.04  0.01 -0.01  0.06  0.15  0.22  0.3   0.26  0.24\n",
            "   0.11  0.19  0.19  0.02  0.03 -0.01 -0.14 -0.22 -0.17 -0.2  -0.31 -0.28\n",
            "  -0.18 -0.24 -0.26 -0.13 -0.19 -0.09  0.01 -0.05 -0.06 -0.03  0.01  0.1\n",
            "   0.01  0.12  0.24  0.14  0.24  0.09  0.08  0.05 -0.01  0.15  0.11  0.19\n",
            "   0.03 -0.04  0.13  0.05  0.02  0.06  0.03  0.08 -0.02  0.15 -0.03  0.02\n",
            "  -0.2   0.11 -0.04 -0.03 -0.01 -0.09  0.03  0.13 -0.13 -0.09 -0.21  0.07\n",
            "   0.16  0.12  0.17 -0.07 -0.17  0.12 -0.05  0.13  0.22 -0.21  0.17 -0.19\n",
            "  -0.11 -0.08  0.18 -0.16  0.1   0.17  0.09 -0.06  0.07 -0.05  0.17 -0.05\n",
            "   0.02 -0.01 -0.06  0.21]\n",
            " [ 0.22  0.3   0.23  0.38  0.16  0.2   0.1   0.19  0.2   0.22 -0.05 -0.09\n",
            "  -0.15 -0.14 -0.19 -0.2  -0.3  -0.17 -0.21 -0.24 -0.07 -0.15 -0.13 -0.06\n",
            "   0.01 -0.05 -0.01  0.11  0.03  0.15  0.05 -0.07  0.16  0.06 -0.05  0.2\n",
            "  -0.03  0.07 -0.08 -0.12  0.08  0.02  0.15  0.1  -0.01 -0.    0.07  0.15\n",
            "  -0.18 -0.02  0.08  0.02  0.17 -0.05 -0.09 -0.14  0.01  0.09  0.2   0.1\n",
            "  -0.09  0.22  0.19 -0.03  0.02 -0.17 -0.04  0.23  0.03  0.02 -0.12 -0.08\n",
            "   0.06 -0.17 -0.03 -0.07  0.22  0.24 -0.2   0.2  -0.09 -0.21 -0.14  0.07\n",
            "   0.09 -0.1  -0.07  0.04 -0.15  0.01  0.07 -0.11  0.23  0.03  0.17 -0.02\n",
            "  -0.23  0.13  0.14 -0.2 ]]\n",
            "Decoder weights \n",
            " [[-0.03 -0.16 -0.23 -0.27 -0.28 -0.29 -0.28 -0.27 -0.26 -0.25 -0.24 -0.22\n",
            "  -0.19 -0.18 -0.18 -0.17 -0.17 -0.17 -0.16 -0.15 -0.13 -0.11 -0.08 -0.04\n",
            "  -0.    0.03  0.06  0.09  0.12  0.15  0.18  0.2   0.22  0.23  0.24  0.24\n",
            "   0.24  0.23  0.22  0.2   0.19  0.17  0.16  0.14  0.12  0.11  0.1   0.08\n",
            "   0.07  0.06  0.05  0.04  0.04  0.05  0.04  0.05  0.01  0.01  0.01  0.\n",
            "   0.01  0.01 -0.   -0.    0.03  0.03  0.03  0.03 -0.01  0.01  0.03 -0.01\n",
            "  -0.01 -0.01 -0.01  0.02  0.01  0.03 -0.02  0.02 -0.01  0.02  0.02  0.02\n",
            "   0.02 -0.02 -0.02 -0.02 -0.02  0.02 -0.    0.02 -0.   -0.02  0.02 -0.01\n",
            "  -0.02  0.01  0.02 -0.02]\n",
            " [-0.02 -0.1  -0.12 -0.12 -0.1  -0.07 -0.01  0.05  0.1   0.14  0.18  0.2\n",
            "   0.21  0.19  0.14  0.08  0.01 -0.06 -0.12 -0.18 -0.23 -0.26 -0.27 -0.27\n",
            "  -0.26 -0.25 -0.22 -0.19 -0.15 -0.11 -0.07 -0.03  0.01  0.04  0.07  0.1\n",
            "   0.11  0.12  0.12  0.12  0.12  0.11  0.11  0.1   0.09  0.08  0.07  0.06\n",
            "   0.06  0.05  0.04  0.03  0.03  0.04  0.03  0.03  0.01  0.   -0.   -0.\n",
            "   0.01  0.01 -0.01 -0.01  0.02  0.02  0.02  0.02 -0.01  0.    0.02 -0.01\n",
            "  -0.01 -0.02 -0.02  0.02  0.    0.02 -0.02  0.02 -0.01  0.02  0.02  0.01\n",
            "   0.02 -0.02 -0.02 -0.02 -0.01  0.02 -0.    0.02  0.01 -0.02  0.01 -0.01\n",
            "  -0.01  0.01  0.01 -0.02]\n",
            " [ 0.05  0.25  0.37  0.43  0.44  0.45  0.39  0.33  0.25  0.17  0.08 -0.02\n",
            "  -0.13 -0.2  -0.24 -0.24 -0.25 -0.23 -0.19 -0.15 -0.11 -0.08 -0.06 -0.04\n",
            "  -0.03 -0.02 -0.01 -0.   -0.   -0.01 -0.02 -0.03 -0.03 -0.05 -0.06 -0.07\n",
            "  -0.07 -0.07 -0.07 -0.07 -0.06 -0.06 -0.06 -0.05 -0.04 -0.04 -0.03 -0.03\n",
            "  -0.02 -0.02 -0.01 -0.   -0.   -0.03 -0.02 -0.04  0.02  0.02  0.02  0.02\n",
            "   0.    0.01  0.03  0.03 -0.03 -0.04 -0.04 -0.03  0.03 -0.   -0.03  0.03\n",
            "   0.03  0.03  0.03 -0.03 -0.02 -0.04  0.04 -0.03  0.03 -0.03 -0.03 -0.03\n",
            "  -0.04  0.04  0.04  0.04  0.03 -0.03  0.   -0.04  0.01  0.04 -0.02  0.02\n",
            "   0.03 -0.01 -0.03  0.04]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGBkPGQHpf7B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "7ad6c814-4dc1-4460-cfb7-61ee2c2f140e"
      },
      "source": [
        "w_pca = pca.components_\n",
        "np.round(np.dot(w_pca, w_pca.T), 3)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1., -0., -0.],\n",
              "       [-0.,  1., -0.],\n",
              "       [-0., -0.,  1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCnVowvIpu2i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "940f141e-ba6f-4f55-8c49-31f18bc26ed2"
      },
      "source": [
        "np.round(np.dot(w_encoder, w_encoder.T), 3)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.042, 0.159, 0.138],\n",
              "       [0.159, 2.383, 0.25 ],\n",
              "       [0.138, 0.25 , 1.539]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wi-F2wUFqIFK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "b2583661-8703-4508-deb8-fe67df5e60de"
      },
      "source": [
        "np.round(np.dot(w_decoder, w_decoder.T), 3)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.145, -0.099,  0.306],\n",
              "       [-0.099,  0.868, -0.253],\n",
              "       [ 0.306, -0.253,  2.699]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fC7q2e77qkuC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "ab64db94-e76c-453a-b3ec-408972e44416"
      },
      "source": [
        "pca_features = pca.fit_transform(X_train_true_norm)\n",
        "np.round(np.cov(pca_features.T), 5)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 2.43e-03, -0.00e+00, -0.00e+00],\n",
              "       [-0.00e+00,  4.10e-04, -0.00e+00],\n",
              "       [-0.00e+00, -0.00e+00,  4.00e-05]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxIQbD5LrDSk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "78374c60-e755-45b9-f46d-93f05e354789"
      },
      "source": [
        "encoder_layer = Model(inputs=autoencoder.inputs, outputs=autoencoder.layers[0].output)\n",
        "encoded_features = np.array(encoder_layer.predict(X_train_true_norm))\n",
        "print('Encoded feature covariance\\n', np.cov(encoded_features.T))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoded feature covariance\n",
            " [[ 0.00078289 -0.00044526 -0.00058556]\n",
            " [-0.00044526  0.00108872  0.00070461]\n",
            " [-0.00058556  0.00070461  0.00062688]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyXdUnoUrt5l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "fb437db9-6d80-4243-b090-7331e8abc320"
      },
      "source": [
        "print('PCA weights norm, \\n', np.sum(w_pca ** 2, axis = 1))\n",
        "print('Encoder weights norm, \\n', np.sum(w_encoder ** 2, axis = 1))\n",
        "print('Decoder weights norm, \\n', np.sum(w_decoder ** 2, axis = 1))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PCA weights norm, \n",
            " [1. 1. 1.]\n",
            "Encoder weights norm, \n",
            " [2.0417006 2.3830006 1.539    ]\n",
            "Decoder weights norm, \n",
            " [1.1450001 0.8684001 2.6994002]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tiiaam3fvhmn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "639d1511-cb70-4c36-ec94-f7ecb0894de9"
      },
      "source": [
        "train_predictions = autoencoder.predict(X_train_true_norm)\n",
        "#print('Train reconstrunction error\\n', sklearn.metrics.mean_squared_error(X_train_scaled, train_predictions))\n",
        "print('Train reconstrunction error\\n', mseTop10(X_train_true_norm, train_predictions))\n",
        "test_predictions = autoencoder.predict(X_test_true_norm)\n",
        "#print('Test reconstrunction error\\n', sklearn.metrics.mean_squared_error(X_test_scaled, test_predictions))\n",
        "print('Test reconstrunction error\\n', mseTop10(X_test_true_norm, test_predictions))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train reconstrunction error\n",
            " tf.Tensor(\n",
            "[1.67759913e-06 6.55572782e-07 1.32211385e-06 ... 9.11456652e-06\n",
            " 8.98501991e-07 3.64721727e-06], shape=(145591,), dtype=float64)\n",
            "Test reconstrunction error\n",
            " tf.Tensor(\n",
            "[5.01978629e-06 8.02176342e-07 6.06355863e-07 ... 1.72796411e-06\n",
            " 1.32675633e-06 2.74711861e-06], shape=(40496,), dtype=float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zK8g_TWDwgFV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import regularizers, activations, initializers, constraints, Sequential\n",
        "class DenseTied(Layer):\n",
        "    def __init__(self, units,\n",
        "                 activation=None,\n",
        "                 use_bias=True,\n",
        "                 kernel_initializer='glorot_uniform',\n",
        "                 bias_initializer='zeros',\n",
        "                 kernel_regularizer=None,\n",
        "                 bias_regularizer=None,\n",
        "                 activity_regularizer=None,\n",
        "                 kernel_constraint=None,\n",
        "                 bias_constraint=None,\n",
        "                 tied_to=None,\n",
        "                 **kwargs):\n",
        "        self.tied_to = tied_to\n",
        "        if 'input_shape' not in kwargs and 'input_dim' in kwargs:\n",
        "            kwargs['input_shape'] = (kwargs.pop('input_dim'),)\n",
        "        super().__init__(**kwargs)\n",
        "        self.units = units\n",
        "        self.activation = activations.get(activation)\n",
        "        self.use_bias = use_bias\n",
        "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
        "        self.bias_initializer = initializers.get(bias_initializer)\n",
        "        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n",
        "        self.bias_regularizer = regularizers.get(bias_regularizer)\n",
        "        self.activity_regularizer = regularizers.get(activity_regularizer)\n",
        "        self.kernel_constraint = constraints.get(kernel_constraint)\n",
        "        self.bias_constraint = constraints.get(bias_constraint)\n",
        "        self.input_spec = InputSpec(min_ndim=2)\n",
        "        self.supports_masking = True\n",
        "                \n",
        "    def build(self, input_shape):\n",
        "        assert len(input_shape) >= 2\n",
        "        input_dim = input_shape[-1]\n",
        "\n",
        "        if self.tied_to is not None:\n",
        "            self.kernel = K.transpose(self.tied_to.kernel)\n",
        "            self._non_trainable_weights.append(self.kernel)\n",
        "        else:\n",
        "            self.kernel = self.add_weight(shape=(input_dim, self.units),\n",
        "                                          initializer=self.kernel_initializer,\n",
        "                                          name='kernel',\n",
        "                                          regularizer=self.kernel_regularizer,\n",
        "                                          constraint=self.kernel_constraint)\n",
        "        if self.use_bias:\n",
        "            self.bias = self.add_weight(shape=(self.units,),\n",
        "                                        initializer=self.bias_initializer,\n",
        "                                        name='bias',\n",
        "                                        regularizer=self.bias_regularizer,\n",
        "                                        constraint=self.bias_constraint)\n",
        "        else:\n",
        "            self.bias = None\n",
        "        self.input_spec = InputSpec(min_ndim=2, axes={-1: input_dim})\n",
        "        self.built = True\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        assert input_shape and len(input_shape) >= 2\n",
        "        output_shape = list(input_shape)\n",
        "        output_shape[-1] = self.units\n",
        "        return tuple(output_shape)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        output = K.dot(inputs, self.kernel)\n",
        "        if self.use_bias:\n",
        "            output = K.bias_add(output, self.bias, data_format='channels_last')\n",
        "        if self.activation is not None:\n",
        "            output = self.activation(output)\n",
        "        return output"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZOHuAiRyx8B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "46761678-180c-4cc7-872c-a635ddea0f8d"
      },
      "source": [
        "encoder = Dense(encoding_dim, activation=\"tanh\", input_shape=(input_dim,), use_bias = True)  #, activity_regularizer=regularizers.l1(learning_rate))(input_layer)\n",
        "#encoder = Dense(hidden_dim, activation=\"tanh\")(encoder)\n",
        "#decoder = Dense(hidden_dim, activation=\"tanh\" )(encoder)\n",
        "#decoder = DenseTied(encoding_dim, activation=\"tanh\", tied_to=encoder, use_bias = True)(decoder)\n",
        "decoder = DenseTied(input_dim, activation=\"tanh\", tied_to=encoder, use_bias = True)\n",
        "autoencoder = Sequential()\n",
        "autoencoder.add(encoder)\n",
        "autoencoder.add(decoder)\n",
        "#autoencoder = Model(inputs=input_layer, outputs=decoder)\n",
        "'''\n",
        "autoencoder.compile(metrics=['accuracy'],\n",
        "                    loss='mean_squared_error',\n",
        "                    optimizer='adam')\n",
        "'''\n",
        "\n",
        "autoencoder.summary()\n",
        "autoencoder.compile(metrics=['accuracy'],\n",
        "                    loss=mseTop10,\n",
        "                    optimizer='adam')\n",
        "history = autoencoder.fit(X_train_true_norm, X_train_true_norm,\n",
        "                    epochs=nb_epoch,\n",
        "                    batch_size=batch_size,\n",
        "                    shuffle=True,\n",
        "                    validation_data=(X_valid_true_norm, X_valid_true_norm),\n",
        "                    verbose=1).history\n",
        "\n"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_14 (Dense)             (None, 3)                 303       \n",
            "_________________________________________________________________\n",
            "dense_tied_4 (DenseTied)     (None, 100)               703       \n",
            "=================================================================\n",
            "Total params: 703\n",
            "Trainable params: 403\n",
            "Non-trainable params: 300\n",
            "_________________________________________________________________\n",
            "Train on 145591 samples, validate on 16212 samples\n",
            "Epoch 1/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 2.6605e-04 - accuracy: 0.0609 - val_loss: 8.6784e-05 - val_accuracy: 0.1553\n",
            "Epoch 2/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 4.8829e-05 - accuracy: 0.2194 - val_loss: 2.6493e-05 - val_accuracy: 0.2598\n",
            "Epoch 3/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1488e-05 - accuracy: 0.2716 - val_loss: 1.7073e-05 - val_accuracy: 0.2968\n",
            "Epoch 4/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 1.3977e-05 - accuracy: 0.3004 - val_loss: 1.0860e-05 - val_accuracy: 0.3195\n",
            "Epoch 5/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 9.2081e-06 - accuracy: 0.3316 - val_loss: 7.2903e-06 - val_accuracy: 0.3465\n",
            "Epoch 6/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 6.5361e-06 - accuracy: 0.3537 - val_loss: 5.4347e-06 - val_accuracy: 0.3566\n",
            "Epoch 7/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 5.1810e-06 - accuracy: 0.3546 - val_loss: 4.5132e-06 - val_accuracy: 0.3560\n",
            "Epoch 8/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 4.4070e-06 - accuracy: 0.3546 - val_loss: 3.8829e-06 - val_accuracy: 0.3633\n",
            "Epoch 9/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 3.9012e-06 - accuracy: 0.3582 - val_loss: 3.5334e-06 - val_accuracy: 0.3624\n",
            "Epoch 10/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 3.6355e-06 - accuracy: 0.3628 - val_loss: 3.3484e-06 - val_accuracy: 0.3714\n",
            "Epoch 11/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 3.4657e-06 - accuracy: 0.3708 - val_loss: 3.2108e-06 - val_accuracy: 0.3738\n",
            "Epoch 12/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 3.3336e-06 - accuracy: 0.3742 - val_loss: 3.0887e-06 - val_accuracy: 0.3782\n",
            "Epoch 13/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 3.2153e-06 - accuracy: 0.3774 - val_loss: 2.9789e-06 - val_accuracy: 0.3799\n",
            "Epoch 14/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 3.0902e-06 - accuracy: 0.3789 - val_loss: 2.8579e-06 - val_accuracy: 0.3787\n",
            "Epoch 15/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.9660e-06 - accuracy: 0.3797 - val_loss: 2.7409e-06 - val_accuracy: 0.3800\n",
            "Epoch 16/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.8428e-06 - accuracy: 0.3819 - val_loss: 2.6302e-06 - val_accuracy: 0.3838\n",
            "Epoch 17/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.7244e-06 - accuracy: 0.3837 - val_loss: 2.5142e-06 - val_accuracy: 0.3874\n",
            "Epoch 18/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.6197e-06 - accuracy: 0.3873 - val_loss: 2.5105e-06 - val_accuracy: 0.3837\n",
            "Epoch 19/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.5219e-06 - accuracy: 0.3903 - val_loss: 2.3316e-06 - val_accuracy: 0.3930\n",
            "Epoch 20/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.4387e-06 - accuracy: 0.3957 - val_loss: 2.2736e-06 - val_accuracy: 0.3966\n",
            "Epoch 21/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.3713e-06 - accuracy: 0.4006 - val_loss: 2.2126e-06 - val_accuracy: 0.4045\n",
            "Epoch 22/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.3171e-06 - accuracy: 0.4058 - val_loss: 2.1618e-06 - val_accuracy: 0.4090\n",
            "Epoch 23/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.2754e-06 - accuracy: 0.4120 - val_loss: 2.1299e-06 - val_accuracy: 0.4127\n",
            "Epoch 24/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.2406e-06 - accuracy: 0.4165 - val_loss: 2.1004e-06 - val_accuracy: 0.4184\n",
            "Epoch 25/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.2158e-06 - accuracy: 0.4236 - val_loss: 2.0771e-06 - val_accuracy: 0.4234\n",
            "Epoch 26/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1911e-06 - accuracy: 0.4280 - val_loss: 2.0595e-06 - val_accuracy: 0.4322\n",
            "Epoch 27/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1772e-06 - accuracy: 0.4326 - val_loss: 2.0544e-06 - val_accuracy: 0.4360\n",
            "Epoch 28/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1651e-06 - accuracy: 0.4373 - val_loss: 2.0501e-06 - val_accuracy: 0.4361\n",
            "Epoch 29/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1558e-06 - accuracy: 0.4421 - val_loss: 2.0395e-06 - val_accuracy: 0.4349\n",
            "Epoch 30/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1703e-06 - accuracy: 0.4467 - val_loss: 2.0278e-06 - val_accuracy: 0.4473\n",
            "Epoch 31/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1579e-06 - accuracy: 0.4520 - val_loss: 2.0187e-06 - val_accuracy: 0.4559\n",
            "Epoch 32/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1401e-06 - accuracy: 0.4566 - val_loss: 2.0171e-06 - val_accuracy: 0.4623\n",
            "Epoch 33/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1351e-06 - accuracy: 0.4596 - val_loss: 2.0219e-06 - val_accuracy: 0.4603\n",
            "Epoch 34/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1341e-06 - accuracy: 0.4613 - val_loss: 2.0139e-06 - val_accuracy: 0.4634\n",
            "Epoch 35/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 2.1404e-06 - accuracy: 0.4627 - val_loss: 2.0266e-06 - val_accuracy: 0.4624\n",
            "Epoch 36/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 2.1337e-06 - accuracy: 0.4635 - val_loss: 2.0121e-06 - val_accuracy: 0.4595\n",
            "Epoch 37/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 2.1329e-06 - accuracy: 0.4640 - val_loss: 2.0134e-06 - val_accuracy: 0.4592\n",
            "Epoch 38/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 2.1312e-06 - accuracy: 0.4626 - val_loss: 2.0184e-06 - val_accuracy: 0.4669\n",
            "Epoch 39/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1435e-06 - accuracy: 0.4647 - val_loss: 2.0211e-06 - val_accuracy: 0.4662\n",
            "Epoch 40/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1318e-06 - accuracy: 0.4657 - val_loss: 2.0116e-06 - val_accuracy: 0.4621\n",
            "Epoch 41/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1313e-06 - accuracy: 0.4649 - val_loss: 2.0200e-06 - val_accuracy: 0.4726\n",
            "Epoch 42/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1369e-06 - accuracy: 0.4645 - val_loss: 2.0395e-06 - val_accuracy: 0.4716\n",
            "Epoch 43/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1544e-06 - accuracy: 0.4640 - val_loss: 2.0081e-06 - val_accuracy: 0.4639\n",
            "Epoch 44/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1360e-06 - accuracy: 0.4651 - val_loss: 2.0212e-06 - val_accuracy: 0.4654\n",
            "Epoch 45/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1356e-06 - accuracy: 0.4638 - val_loss: 2.0262e-06 - val_accuracy: 0.4508\n",
            "Epoch 46/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1318e-06 - accuracy: 0.4645 - val_loss: 2.0141e-06 - val_accuracy: 0.4746\n",
            "Epoch 47/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1480e-06 - accuracy: 0.4642 - val_loss: 2.0160e-06 - val_accuracy: 0.4566\n",
            "Epoch 48/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1316e-06 - accuracy: 0.4639 - val_loss: 2.0189e-06 - val_accuracy: 0.4673\n",
            "Epoch 49/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1330e-06 - accuracy: 0.4644 - val_loss: 2.0108e-06 - val_accuracy: 0.4651\n",
            "Epoch 50/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1338e-06 - accuracy: 0.4622 - val_loss: 2.0187e-06 - val_accuracy: 0.4734\n",
            "Epoch 51/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 2.1439e-06 - accuracy: 0.4629 - val_loss: 2.0200e-06 - val_accuracy: 0.4674\n",
            "Epoch 52/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 2.1812e-06 - accuracy: 0.4624 - val_loss: 2.0242e-06 - val_accuracy: 0.4620\n",
            "Epoch 53/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 2.1686e-06 - accuracy: 0.4621 - val_loss: 2.0204e-06 - val_accuracy: 0.4733\n",
            "Epoch 54/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 2.1411e-06 - accuracy: 0.4622 - val_loss: 2.0121e-06 - val_accuracy: 0.4627\n",
            "Epoch 55/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 2.1315e-06 - accuracy: 0.4607 - val_loss: 2.0331e-06 - val_accuracy: 0.4668\n",
            "Epoch 56/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 2.1787e-06 - accuracy: 0.4625 - val_loss: 2.0216e-06 - val_accuracy: 0.4573\n",
            "Epoch 57/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 2.1521e-06 - accuracy: 0.4594 - val_loss: 2.0106e-06 - val_accuracy: 0.4642\n",
            "Epoch 58/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.2024e-06 - accuracy: 0.4603 - val_loss: 2.0160e-06 - val_accuracy: 0.4590\n",
            "Epoch 59/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1344e-06 - accuracy: 0.4631 - val_loss: 2.0115e-06 - val_accuracy: 0.4480\n",
            "Epoch 60/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1522e-06 - accuracy: 0.4631 - val_loss: 2.0674e-06 - val_accuracy: 0.4392\n",
            "Epoch 61/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1612e-06 - accuracy: 0.4618 - val_loss: 2.0110e-06 - val_accuracy: 0.4491\n",
            "Epoch 62/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1443e-06 - accuracy: 0.4604 - val_loss: 2.0088e-06 - val_accuracy: 0.4616\n",
            "Epoch 63/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1702e-06 - accuracy: 0.4614 - val_loss: 2.1740e-06 - val_accuracy: 0.4481\n",
            "Epoch 64/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1452e-06 - accuracy: 0.4593 - val_loss: 2.0208e-06 - val_accuracy: 0.4526\n",
            "Epoch 65/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1511e-06 - accuracy: 0.4615 - val_loss: 2.0212e-06 - val_accuracy: 0.4584\n",
            "Epoch 66/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1629e-06 - accuracy: 0.4621 - val_loss: 2.0170e-06 - val_accuracy: 0.4625\n",
            "Epoch 67/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1341e-06 - accuracy: 0.4605 - val_loss: 2.1199e-06 - val_accuracy: 0.4679\n",
            "Epoch 68/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1411e-06 - accuracy: 0.4592 - val_loss: 2.0171e-06 - val_accuracy: 0.4555\n",
            "Epoch 69/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1361e-06 - accuracy: 0.4606 - val_loss: 2.0199e-06 - val_accuracy: 0.4629\n",
            "Epoch 70/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1586e-06 - accuracy: 0.4598 - val_loss: 2.0161e-06 - val_accuracy: 0.4660\n",
            "Epoch 71/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1354e-06 - accuracy: 0.4614 - val_loss: 2.0225e-06 - val_accuracy: 0.4673\n",
            "Epoch 72/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1483e-06 - accuracy: 0.4631 - val_loss: 2.0169e-06 - val_accuracy: 0.4565\n",
            "Epoch 73/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1311e-06 - accuracy: 0.4628 - val_loss: 2.0188e-06 - val_accuracy: 0.4545\n",
            "Epoch 74/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1452e-06 - accuracy: 0.4579 - val_loss: 2.0326e-06 - val_accuracy: 0.4610\n",
            "Epoch 75/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1579e-06 - accuracy: 0.4601 - val_loss: 2.0207e-06 - val_accuracy: 0.4645\n",
            "Epoch 76/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1342e-06 - accuracy: 0.4620 - val_loss: 2.0097e-06 - val_accuracy: 0.4562\n",
            "Epoch 77/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1357e-06 - accuracy: 0.4614 - val_loss: 2.0194e-06 - val_accuracy: 0.4526\n",
            "Epoch 78/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1364e-06 - accuracy: 0.4597 - val_loss: 2.0172e-06 - val_accuracy: 0.4577\n",
            "Epoch 79/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1364e-06 - accuracy: 0.4616 - val_loss: 2.0283e-06 - val_accuracy: 0.4455\n",
            "Epoch 80/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1419e-06 - accuracy: 0.4616 - val_loss: 2.0253e-06 - val_accuracy: 0.4622\n",
            "Epoch 81/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1345e-06 - accuracy: 0.4582 - val_loss: 2.0147e-06 - val_accuracy: 0.4576\n",
            "Epoch 82/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1337e-06 - accuracy: 0.4581 - val_loss: 2.0240e-06 - val_accuracy: 0.4438\n",
            "Epoch 83/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1572e-06 - accuracy: 0.4616 - val_loss: 2.0222e-06 - val_accuracy: 0.4643\n",
            "Epoch 84/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1338e-06 - accuracy: 0.4595 - val_loss: 2.0275e-06 - val_accuracy: 0.4638\n",
            "Epoch 85/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1438e-06 - accuracy: 0.4595 - val_loss: 2.0207e-06 - val_accuracy: 0.4590\n",
            "Epoch 86/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1368e-06 - accuracy: 0.4607 - val_loss: 2.0152e-06 - val_accuracy: 0.4547\n",
            "Epoch 87/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1339e-06 - accuracy: 0.4601 - val_loss: 2.0242e-06 - val_accuracy: 0.4492\n",
            "Epoch 88/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1326e-06 - accuracy: 0.4612 - val_loss: 2.0141e-06 - val_accuracy: 0.4529\n",
            "Epoch 89/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1357e-06 - accuracy: 0.4604 - val_loss: 2.0161e-06 - val_accuracy: 0.4490\n",
            "Epoch 90/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1356e-06 - accuracy: 0.4603 - val_loss: 2.0227e-06 - val_accuracy: 0.4537\n",
            "Epoch 91/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1504e-06 - accuracy: 0.4613 - val_loss: 2.0112e-06 - val_accuracy: 0.4578\n",
            "Epoch 92/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1370e-06 - accuracy: 0.4592 - val_loss: 2.0272e-06 - val_accuracy: 0.4613\n",
            "Epoch 93/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1489e-06 - accuracy: 0.4591 - val_loss: 2.0338e-06 - val_accuracy: 0.4631\n",
            "Epoch 94/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1442e-06 - accuracy: 0.4624 - val_loss: 2.0204e-06 - val_accuracy: 0.4476\n",
            "Epoch 95/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1401e-06 - accuracy: 0.4606 - val_loss: 2.0143e-06 - val_accuracy: 0.4655\n",
            "Epoch 96/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1351e-06 - accuracy: 0.4605 - val_loss: 2.0181e-06 - val_accuracy: 0.4704\n",
            "Epoch 97/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1460e-06 - accuracy: 0.4587 - val_loss: 2.1339e-06 - val_accuracy: 0.4676\n",
            "Epoch 98/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1368e-06 - accuracy: 0.4617 - val_loss: 2.1119e-06 - val_accuracy: 0.4547\n",
            "Epoch 99/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1439e-06 - accuracy: 0.4584 - val_loss: 2.0124e-06 - val_accuracy: 0.4581\n",
            "Epoch 100/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1392e-06 - accuracy: 0.4602 - val_loss: 2.0219e-06 - val_accuracy: 0.4585\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAImru8n4O-l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 834
        },
        "outputId": "92f84154-79ed-4494-e520-ac1b98b20150"
      },
      "source": [
        "#w_encoder = np.round(np.transpose(autoencoder.layers[0].get_weights()[0]), 3)\n",
        "#w_decoder = np.round(autoencoder.layers[1].get_weights()[0], 3)\n",
        "#print('Encoder weights\\n', w_encoder)\n",
        "#print('Decoder weights\\n', w_decoder)\n",
        "#print(autoencoder.layers[0].get_weights()[0])\n",
        "w_encoder = np.round(autoencoder.layers[0].get_weights()[0], 2).T  # W in Figure 3.\n",
        "#w_decoder = np.round(autoencoder.layers[1].get_weights()[0], 2)  # W' in Figure 3.\n",
        "print('Encoder weights \\n', w_encoder)\n",
        "#print('Decoder weights \\n', w_decoder)\n",
        "w_decoder = np.round(autoencoder.layers[1].get_weights()[0], 3)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder weights \n",
            " [[ 0.04  0.1   0.13  0.13  0.11  0.07  0.01 -0.06 -0.12 -0.19 -0.24 -0.29\n",
            "  -0.32 -0.32 -0.29 -0.24 -0.18 -0.12 -0.05  0.02  0.08  0.13  0.16  0.19\n",
            "   0.2   0.21  0.21  0.2   0.18  0.16  0.14  0.11  0.08  0.06  0.03  0.01\n",
            "   0.   -0.   -0.01 -0.02 -0.02 -0.02 -0.02 -0.02 -0.02 -0.01 -0.01 -0.01\n",
            "  -0.    0.    0.01  0.01  0.01  0.01  0.   -0.    0.01  0.01  0.01  0.01\n",
            "   0.01  0.01 -0.01 -0.01  0.01 -0.01  0.    0.01  0.01 -0.02  0.01 -0.02\n",
            "  -0.01  0.01  0.01 -0.01  0.01  0.    0.   -0.02 -0.01 -0.02  0.    0.01\n",
            "  -0.02  0.01  0.01  0.01  0.01 -0.02 -0.01 -0.02 -0.01 -0.    0.01 -0.02\n",
            "  -0.01  0.01 -0.01  0.01]\n",
            " [ 0.04  0.14  0.21  0.25  0.28  0.29  0.27  0.25  0.21  0.16  0.1   0.04\n",
            "  -0.04 -0.1  -0.15 -0.19 -0.22 -0.23 -0.23 -0.23 -0.21 -0.2  -0.19 -0.17\n",
            "  -0.15 -0.12 -0.1  -0.08 -0.06 -0.04 -0.03 -0.02 -0.01  0.    0.01  0.02\n",
            "   0.03  0.04  0.04  0.04  0.04  0.04  0.03  0.03  0.03  0.03  0.03  0.03\n",
            "   0.03  0.03  0.03  0.02  0.02  0.02  0.02  0.01  0.01  0.01  0.01  0.01\n",
            "   0.01  0.01 -0.01 -0.01  0.01 -0.01  0.02  0.01  0.01 -0.01  0.02 -0.01\n",
            "  -0.01  0.01  0.01 -0.    0.01  0.01  0.   -0.01 -0.01 -0.01  0.01  0.02\n",
            "  -0.02  0.01  0.01  0.01  0.01 -0.01 -0.02 -0.02 -0.01 -0.    0.02 -0.02\n",
            "  -0.01  0.01 -0.02  0.01]\n",
            " [ 0.05  0.15  0.21  0.23  0.23  0.22  0.18  0.15  0.13  0.11  0.08  0.07\n",
            "   0.05  0.04  0.07  0.1   0.12  0.14  0.16  0.18  0.19  0.18  0.16  0.14\n",
            "   0.11  0.08  0.05  0.01 -0.03 -0.06 -0.1  -0.13 -0.16 -0.18 -0.2  -0.21\n",
            "  -0.21 -0.2  -0.19 -0.18 -0.17 -0.15 -0.14 -0.12 -0.11 -0.1  -0.08 -0.07\n",
            "  -0.06 -0.05 -0.04 -0.03 -0.03 -0.02 -0.02 -0.02 -0.01 -0.01 -0.01 -0.\n",
            "  -0.   -0.   -0.02 -0.02 -0.   -0.03 -0.    0.    0.   -0.03  0.   -0.03\n",
            "  -0.02  0.    0.   -0.01  0.01  0.01 -0.   -0.02 -0.01 -0.02  0.01  0.\n",
            "  -0.02  0.01  0.01  0.01  0.01 -0.02 -0.02 -0.02 -0.02 -0.    0.01 -0.02\n",
            "  -0.01  0.01 -0.02  0.01]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-6c0a6d015146>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Encoder weights \\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_encoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#print('Decoder weights \\n', w_decoder)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mw_decoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36meager_fn_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0m_SYMBOLIC_SCOPE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0m_SYMBOLIC_SCOPE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprev_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36mget_weights\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1136\u001b[0m         \"\"\"\n\u001b[1;32m   1137\u001b[0m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1138\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mbatch_get_value\u001b[0;34m(ops)\u001b[0m\n\u001b[1;32m   2937\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mNumpy\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2938\u001b[0m     \"\"\"\n\u001b[0;32m-> 2939\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf_keras_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2940\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2941\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mbatch_get_value\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m   3325\u001b[0m   \"\"\"\n\u001b[1;32m   3326\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3327\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3328\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3329\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot get value inside Tensorflow graph function.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   3325\u001b[0m   \"\"\"\n\u001b[1;32m   3326\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3327\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3328\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3329\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot get value inside Tensorflow graph function.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'numpy'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVbm4na2Dtxt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "af280586-7d43-44ef-e2bc-68f2194091e3"
      },
      "source": [
        "b_encoder = np.round(np.transpose(autoencoder.layers[0].get_weights()[1]), 3)\n",
        "#b_decoder = np.round(np.transpose(autoencoder.layers[1].get_weights()[0]), 3)\n",
        "print('Encoder bias\\n', b_encoder)\n",
        "#print('Decoder bias\\n', b_decoder)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder bias\n",
            " [ 0.016  0.051 -0.045]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAxdF2g_D9Jt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class WeightsOrthogonalityConstraint (Constraint):\n",
        "    def __init__(self, encoding_dim, weightage = 1.0, axis = 0):\n",
        "        self.encoding_dim = encoding_dim\n",
        "        self.weightage = weightage\n",
        "        self.axis = axis\n",
        "        \n",
        "    def weights_orthogonality(self, w):\n",
        "        if(self.axis==1):\n",
        "            w = K.transpose(w)\n",
        "        if(self.encoding_dim > 1):\n",
        "            m = K.dot(K.transpose(w), w) - K.eye(self.encoding_dim)\n",
        "            return self.weightage * K.sqrt(K.sum(K.square(m)))\n",
        "        else:\n",
        "            m = K.sum(w ** 2) - 1.\n",
        "            return m\n",
        "\n",
        "    def __call__(self, w):\n",
        "        return self.weights_orthogonality(w)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RntzKcV0EC4w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "94150556-4907-4536-d8bb-30066fac67aa"
      },
      "source": [
        "encoder = Dense(encoding_dim, activation=\"tanh\", input_shape=(input_dim,), use_bias = True,   kernel_regularizer=WeightsOrthogonalityConstraint(encoding_dim, weightage=1., axis=0) )\n",
        "#encoder = Dense(hidden_dim, activation=\"tanh\")(encoder)\n",
        "#decoder = Dense(hidden_dim, activation=\"tanh\" )(encoder)\n",
        "#decoder = DenseTied(encoding_dim, activation=\"tanh\", tied_to=encoder, use_bias = True)(decoder)\n",
        "decoder = Dense(input_dim, activation=\"tanh\", use_bias = True,\n",
        "kernel_regularizer=WeightsOrthogonalityConstraint(encoding_dim, weightage=1., axis=1))\n",
        "\n",
        "autoencoder = Sequential()\n",
        "autoencoder.add(encoder)\n",
        "autoencoder.add(decoder)\n",
        "#autoencoder = Model(inputs=input_layer, outputs=decoder)\n",
        "'''\n",
        "autoencoder.compile(metrics=['accuracy'],\n",
        "                    loss='mean_squared_error',\n",
        "                    optimizer='adam')\n",
        "'''\n",
        "\n",
        "autoencoder.summary()\n",
        "autoencoder.compile(metrics=['accuracy'],\n",
        "                    loss=mseTop10,\n",
        "                    optimizer='adam')\n",
        "history = autoencoder.fit(X_train_true_norm, X_train_true_norm,\n",
        "                    epochs=nb_epoch,\n",
        "                    batch_size=batch_size,\n",
        "                    shuffle=True,\n",
        "                    validation_data=(X_valid_true_norm, X_valid_true_norm),\n",
        "                    verbose=1).history\n",
        "\n"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_16 (Dense)             (None, 3)                 303       \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 100)               400       \n",
            "=================================================================\n",
            "Total params: 703\n",
            "Trainable params: 703\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 145591 samples, validate on 16212 samples\n",
            "Epoch 1/100\n",
            "145591/145591 [==============================] - 1s 10us/step - loss: 0.4997 - accuracy: 0.1056 - val_loss: 0.0045 - val_accuracy: 0.1424\n",
            "Epoch 2/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 0.0036 - accuracy: 0.1447 - val_loss: 0.0038 - val_accuracy: 0.1490\n",
            "Epoch 3/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 0.0046 - accuracy: 0.1450 - val_loss: 0.0041 - val_accuracy: 0.1405\n",
            "Epoch 4/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 0.0041 - accuracy: 0.1435 - val_loss: 0.0049 - val_accuracy: 0.1374\n",
            "Epoch 5/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 0.0035 - accuracy: 0.1439 - val_loss: 0.0033 - val_accuracy: 0.1487\n",
            "Epoch 6/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 0.0037 - accuracy: 0.1445 - val_loss: 0.0035 - val_accuracy: 0.1406\n",
            "Epoch 7/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 0.0043 - accuracy: 0.1425 - val_loss: 0.0045 - val_accuracy: 0.1469\n",
            "Epoch 8/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 0.0033 - accuracy: 0.1412 - val_loss: 0.0030 - val_accuracy: 0.1422\n",
            "Epoch 9/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 0.0031 - accuracy: 0.1396 - val_loss: 0.0034 - val_accuracy: 0.1458\n",
            "Epoch 10/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 0.0037 - accuracy: 0.1415 - val_loss: 0.0035 - val_accuracy: 0.1337\n",
            "Epoch 11/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 0.0046 - accuracy: 0.1406 - val_loss: 0.0049 - val_accuracy: 0.1390\n",
            "Epoch 12/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 0.0037 - accuracy: 0.1403 - val_loss: 0.0034 - val_accuracy: 0.1472\n",
            "Epoch 13/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 0.0033 - accuracy: 0.1424 - val_loss: 0.0028 - val_accuracy: 0.1468\n",
            "Epoch 14/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 0.0041 - accuracy: 0.1393 - val_loss: 0.0029 - val_accuracy: 0.1154\n",
            "Epoch 15/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 0.0044 - accuracy: 0.1393 - val_loss: 0.0041 - val_accuracy: 0.1352\n",
            "Epoch 16/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 0.0038 - accuracy: 0.1394 - val_loss: 0.0033 - val_accuracy: 0.1445\n",
            "Epoch 17/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 0.0034 - accuracy: 0.1399 - val_loss: 0.0033 - val_accuracy: 0.1286\n",
            "Epoch 18/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 0.0032 - accuracy: 0.1370 - val_loss: 0.0044 - val_accuracy: 0.1299\n",
            "Epoch 19/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 0.0037 - accuracy: 0.1366 - val_loss: 0.0041 - val_accuracy: 0.1441\n",
            "Epoch 20/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 0.0041 - accuracy: 0.1407 - val_loss: 0.0042 - val_accuracy: 0.1340\n",
            "Epoch 21/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 0.0039 - accuracy: 0.1402 - val_loss: 0.0032 - val_accuracy: 0.1319\n",
            "Epoch 22/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 0.0035 - accuracy: 0.1404 - val_loss: 0.0034 - val_accuracy: 0.1426\n",
            "Epoch 23/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 0.0042 - accuracy: 0.1341 - val_loss: 0.0047 - val_accuracy: 0.1442\n",
            "Epoch 24/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 0.0041 - accuracy: 0.1373 - val_loss: 0.0038 - val_accuracy: 0.1477\n",
            "Epoch 25/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 0.0043 - accuracy: 0.1357 - val_loss: 0.0040 - val_accuracy: 0.1431\n",
            "Epoch 26/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 0.0034 - accuracy: 0.1301 - val_loss: 0.0036 - val_accuracy: 0.1088\n",
            "Epoch 27/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 0.0035 - accuracy: 0.1350 - val_loss: 0.0035 - val_accuracy: 0.1319\n",
            "Epoch 28/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 0.0053 - accuracy: 0.1359 - val_loss: 0.0041 - val_accuracy: 0.1461\n",
            "Epoch 29/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 0.0042 - accuracy: 0.1353 - val_loss: 0.0034 - val_accuracy: 0.1137\n",
            "Epoch 30/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 0.0043 - accuracy: 0.1326 - val_loss: 0.0029 - val_accuracy: 0.1295\n",
            "Epoch 31/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 0.0054 - accuracy: 0.1407 - val_loss: 0.0070 - val_accuracy: 0.1319\n",
            "Epoch 32/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 0.0057 - accuracy: 0.1398 - val_loss: 0.0037 - val_accuracy: 0.1422\n",
            "Epoch 33/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 0.0044 - accuracy: 0.1350 - val_loss: 0.0038 - val_accuracy: 0.1279\n",
            "Epoch 34/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 0.0037 - accuracy: 0.1359 - val_loss: 0.0027 - val_accuracy: 0.1502\n",
            "Epoch 35/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 0.0051 - accuracy: 0.1389 - val_loss: 0.0057 - val_accuracy: 0.1347\n",
            "Epoch 36/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 0.0042 - accuracy: 0.1371 - val_loss: 0.0080 - val_accuracy: 0.1313\n",
            "Epoch 37/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 0.0054 - accuracy: 0.1320 - val_loss: 0.0042 - val_accuracy: 0.1374\n",
            "Epoch 38/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 0.0043 - accuracy: 0.1341 - val_loss: 0.0035 - val_accuracy: 0.1460\n",
            "Epoch 39/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 0.0038 - accuracy: 0.1361 - val_loss: 0.0037 - val_accuracy: 0.1418\n",
            "Epoch 40/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 0.0038 - accuracy: 0.1400 - val_loss: 0.0040 - val_accuracy: 0.1271\n",
            "Epoch 41/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 0.0039 - accuracy: 0.1381 - val_loss: 0.0050 - val_accuracy: 0.0977\n",
            "Epoch 42/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 0.0048 - accuracy: 0.1317 - val_loss: 0.0048 - val_accuracy: 0.0461\n",
            "Epoch 43/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 0.0051 - accuracy: 0.1337 - val_loss: 0.0049 - val_accuracy: 0.1313\n",
            "Epoch 44/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 0.0040 - accuracy: 0.1376 - val_loss: 0.0036 - val_accuracy: 0.1372\n",
            "Epoch 45/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 0.0036 - accuracy: 0.1320 - val_loss: 0.0065 - val_accuracy: 0.1339\n",
            "Epoch 46/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 0.0037 - accuracy: 0.1348 - val_loss: 0.0028 - val_accuracy: 0.1314\n",
            "Epoch 47/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 0.0039 - accuracy: 0.1365 - val_loss: 0.0077 - val_accuracy: 0.1457\n",
            "Epoch 48/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 0.0037 - accuracy: 0.1363 - val_loss: 0.0031 - val_accuracy: 0.1360\n",
            "Epoch 49/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 0.0039 - accuracy: 0.1367 - val_loss: 0.0040 - val_accuracy: 0.1505\n",
            "Epoch 50/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 0.0042 - accuracy: 0.1332 - val_loss: 0.0044 - val_accuracy: 0.1332\n",
            "Epoch 51/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 0.0042 - accuracy: 0.1278 - val_loss: 0.0035 - val_accuracy: 0.1363\n",
            "Epoch 52/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 0.0045 - accuracy: 0.1340 - val_loss: 0.0067 - val_accuracy: 0.1231\n",
            "Epoch 53/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 0.0039 - accuracy: 0.1296 - val_loss: 0.0046 - val_accuracy: 0.1298\n",
            "Epoch 54/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 0.0046 - accuracy: 0.1216 - val_loss: 0.0035 - val_accuracy: 0.1284\n",
            "Epoch 55/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 0.0039 - accuracy: 0.1314 - val_loss: 0.0029 - val_accuracy: 0.1450\n",
            "Epoch 56/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 0.0034 - accuracy: 0.1348 - val_loss: 0.0045 - val_accuracy: 0.1268\n",
            "Epoch 57/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 0.0041 - accuracy: 0.1295 - val_loss: 0.0055 - val_accuracy: 0.1356\n",
            "Epoch 58/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 0.0043 - accuracy: 0.1357 - val_loss: 0.0059 - val_accuracy: 0.1277\n",
            "Epoch 59/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 0.0054 - accuracy: 0.1271 - val_loss: 0.0047 - val_accuracy: 0.1136\n",
            "Epoch 60/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 0.0039 - accuracy: 0.1333 - val_loss: 0.0041 - val_accuracy: 0.0714\n",
            "Epoch 61/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 0.0035 - accuracy: 0.1335 - val_loss: 0.0028 - val_accuracy: 0.1364\n",
            "Epoch 62/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 0.0034 - accuracy: 0.1290 - val_loss: 0.0030 - val_accuracy: 0.1330\n",
            "Epoch 63/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 0.0039 - accuracy: 0.1321 - val_loss: 0.0030 - val_accuracy: 0.1360\n",
            "Epoch 64/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 0.0038 - accuracy: 0.1305 - val_loss: 0.0030 - val_accuracy: 0.1303\n",
            "Epoch 65/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 0.0039 - accuracy: 0.1316 - val_loss: 0.0040 - val_accuracy: 0.0804\n",
            "Epoch 66/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 0.0037 - accuracy: 0.1311 - val_loss: 0.0040 - val_accuracy: 0.1116\n",
            "Epoch 67/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 0.0044 - accuracy: 0.1337 - val_loss: 0.0030 - val_accuracy: 0.1281\n",
            "Epoch 68/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 0.0037 - accuracy: 0.1319 - val_loss: 0.0029 - val_accuracy: 0.1475\n",
            "Epoch 69/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 0.0037 - accuracy: 0.1319 - val_loss: 0.0037 - val_accuracy: 0.1349\n",
            "Epoch 70/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 0.0035 - accuracy: 0.1354 - val_loss: 0.0033 - val_accuracy: 0.1494\n",
            "Epoch 71/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 0.0043 - accuracy: 0.1381 - val_loss: 0.0061 - val_accuracy: 0.1287\n",
            "Epoch 72/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 0.0039 - accuracy: 0.1272 - val_loss: 0.0029 - val_accuracy: 0.1303\n",
            "Epoch 73/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 0.0037 - accuracy: 0.1295 - val_loss: 0.0038 - val_accuracy: 0.0748\n",
            "Epoch 74/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 0.0034 - accuracy: 0.1337 - val_loss: 0.0030 - val_accuracy: 0.1417\n",
            "Epoch 75/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 0.0036 - accuracy: 0.1330 - val_loss: 0.0035 - val_accuracy: 0.1266\n",
            "Epoch 76/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 0.0043 - accuracy: 0.1287 - val_loss: 0.0058 - val_accuracy: 0.1473\n",
            "Epoch 77/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 0.0038 - accuracy: 0.1336 - val_loss: 0.0031 - val_accuracy: 0.1448\n",
            "Epoch 78/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 0.0041 - accuracy: 0.1307 - val_loss: 0.0055 - val_accuracy: 0.1315\n",
            "Epoch 79/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 0.0042 - accuracy: 0.1331 - val_loss: 0.0032 - val_accuracy: 0.1462\n",
            "Epoch 80/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 0.0040 - accuracy: 0.1307 - val_loss: 0.0047 - val_accuracy: 0.1432\n",
            "Epoch 81/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 0.0046 - accuracy: 0.1344 - val_loss: 0.0074 - val_accuracy: 0.1267\n",
            "Epoch 82/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 0.0044 - accuracy: 0.1253 - val_loss: 0.0046 - val_accuracy: 0.1286\n",
            "Epoch 83/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 0.0041 - accuracy: 0.1307 - val_loss: 0.0035 - val_accuracy: 0.1339\n",
            "Epoch 84/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 0.0037 - accuracy: 0.1368 - val_loss: 0.0037 - val_accuracy: 0.1281\n",
            "Epoch 85/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 0.0034 - accuracy: 0.1283 - val_loss: 0.0028 - val_accuracy: 0.1273\n",
            "Epoch 86/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 0.0036 - accuracy: 0.1342 - val_loss: 0.0050 - val_accuracy: 0.0680\n",
            "Epoch 87/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 0.0041 - accuracy: 0.1296 - val_loss: 0.0042 - val_accuracy: 0.1277\n",
            "Epoch 88/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 0.0047 - accuracy: 0.1229 - val_loss: 0.0032 - val_accuracy: 0.1453\n",
            "Epoch 89/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 0.0036 - accuracy: 0.1350 - val_loss: 0.0031 - val_accuracy: 0.1451\n",
            "Epoch 90/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 0.0033 - accuracy: 0.1343 - val_loss: 0.0053 - val_accuracy: 0.1298\n",
            "Epoch 91/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 0.0052 - accuracy: 0.1333 - val_loss: 0.0058 - val_accuracy: 0.1453\n",
            "Epoch 92/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 0.0046 - accuracy: 0.1332 - val_loss: 0.0045 - val_accuracy: 0.1476\n",
            "Epoch 93/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 0.0041 - accuracy: 0.1317 - val_loss: 0.0037 - val_accuracy: 0.1350\n",
            "Epoch 94/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 0.0043 - accuracy: 0.1260 - val_loss: 0.0040 - val_accuracy: 0.1268\n",
            "Epoch 95/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 0.0036 - accuracy: 0.1262 - val_loss: 0.0035 - val_accuracy: 0.1423\n",
            "Epoch 96/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 0.0033 - accuracy: 0.1342 - val_loss: 0.0084 - val_accuracy: 0.1366\n",
            "Epoch 97/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 0.0046 - accuracy: 0.1274 - val_loss: 0.0032 - val_accuracy: 0.1267\n",
            "Epoch 98/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 0.0044 - accuracy: 0.1265 - val_loss: 0.0047 - val_accuracy: 0.1322\n",
            "Epoch 99/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 0.0042 - accuracy: 0.1305 - val_loss: 0.0040 - val_accuracy: 0.1436\n",
            "Epoch 100/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 0.0039 - accuracy: 0.1321 - val_loss: 0.0038 - val_accuracy: 0.1284\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCjUZHrQFIgD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "52f96863-3787-4926-93d0-1f7a17555317"
      },
      "source": [
        "w_encoder = autoencoder.layers[0].get_weights()[0]\n",
        "print('Encoder weights dot product\\n', np.round(np.dot(w_encoder.T, w_encoder), 2))\n",
        "\n",
        "w_decoder = autoencoder.layers[1].get_weights()[0]\n",
        "print('Decoder weights dot product\\n', np.round(np.dot(w_decoder, w_decoder.T), 2))"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder weights dot product\n",
            " [[ 1. -0. -0.]\n",
            " [-0.  1. -0.]\n",
            " [-0. -0.  1.]]\n",
            "Decoder weights dot product\n",
            " [[ 1.  0.  0.]\n",
            " [ 0.  1. -0.]\n",
            " [ 0. -0.  1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77Kr2DanFOPK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class UncorrelatedFeaturesConstraint (Constraint):\n",
        "    \n",
        "    def __init__(self, encoding_dim, weightage = 1.0):\n",
        "        self.encoding_dim = encoding_dim\n",
        "        self.weightage = weightage\n",
        "    \n",
        "    def get_covariance(self, x):\n",
        "        x_centered_list = []\n",
        "\n",
        "        for i in range(self.encoding_dim):\n",
        "            x_centered_list.append(x[:, i] - K.mean(x[:, i]))\n",
        "        \n",
        "        x_centered = tf.stack(x_centered_list)\n",
        "        covariance = K.dot(x_centered, K.transpose(x_centered)) / tf.cast(x_centered.get_shape()[0], tf.float32)\n",
        "        \n",
        "        return covariance\n",
        "            \n",
        "    # Constraint penalty\n",
        "    def uncorrelated_feature(self, x):\n",
        "        if(self.encoding_dim <= 1):\n",
        "            return 0.0\n",
        "        else:\n",
        "            output = K.sum(K.square(\n",
        "                self.covariance - tf.math.multiply(self.covariance, K.eye(self.encoding_dim))))\n",
        "            return output\n",
        "\n",
        "    def __call__(self, x):\n",
        "        self.covariance = self.get_covariance(x)\n",
        "        return self.weightage * self.uncorrelated_feature(x)"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wf2v1qyPFS-p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cb4eea29-a0f4-485a-9df4-529c68268c78"
      },
      "source": [
        "encoder = Dense(encoding_dim, activation=\"tanh\", input_shape=(input_dim,), use_bias = True,   \n",
        "                activity_regularizer=UncorrelatedFeaturesConstraint(encoding_dim, weightage = 1.) )\n",
        "#encoder = Dense(hidden_dim, activation=\"tanh\")(encoder)\n",
        "#decoder = Dense(hidden_dim, activation=\"tanh\" )(encoder)\n",
        "#decoder = DenseTied(encoding_dim, activation=\"tanh\", tied_to=encoder, use_bias = True)(decoder)\n",
        "decoder = Dense(input_dim, activation=\"tanh\", use_bias = True)\n",
        "\n",
        "autoencoder = Sequential()\n",
        "autoencoder.add(encoder)\n",
        "autoencoder.add(decoder)\n",
        "#autoencoder = Model(inputs=input_layer, outputs=decoder)\n",
        "'''\n",
        "autoencoder.compile(metrics=['accuracy'],\n",
        "                    loss='mean_squared_error',\n",
        "                    optimizer='adam')\n",
        "'''\n",
        "\n",
        "autoencoder.summary()\n",
        "autoencoder.compile(metrics=['accuracy'],\n",
        "                    loss=mseTop10,\n",
        "                    optimizer='adam')\n",
        "history = autoencoder.fit(X_train_true_norm, X_train_true_norm,\n",
        "                    epochs=nb_epoch,\n",
        "                    batch_size=batch_size,\n",
        "                    shuffle=True,\n",
        "                    validation_data=(X_valid_true_norm, X_valid_true_norm),\n",
        "                    verbose=1).history\n",
        "\n"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_18 (Dense)             (None, 3)                 303       \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 100)               400       \n",
            "=================================================================\n",
            "Total params: 703\n",
            "Trainable params: 703\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 145591 samples, validate on 16212 samples\n",
            "Epoch 1/100\n",
            "145591/145591 [==============================] - 1s 10us/step - loss: 3.3556e-04 - accuracy: 0.1279 - val_loss: 1.4960e-04 - val_accuracy: 0.1887\n",
            "Epoch 2/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 1.3698e-04 - accuracy: 0.1771 - val_loss: 1.2092e-04 - val_accuracy: 0.1787\n",
            "Epoch 3/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 9.9506e-05 - accuracy: 0.1682 - val_loss: 7.7610e-05 - val_accuracy: 0.1751\n",
            "Epoch 4/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 5.9791e-05 - accuracy: 0.1753 - val_loss: 4.7966e-05 - val_accuracy: 0.1952\n",
            "Epoch 5/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 3.9343e-05 - accuracy: 0.2326 - val_loss: 3.2562e-05 - val_accuracy: 0.3057\n",
            "Epoch 6/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 3.2960e-05 - accuracy: 0.3214 - val_loss: 2.6819e-05 - val_accuracy: 0.3328\n",
            "Epoch 7/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 2.8015e-05 - accuracy: 0.3440 - val_loss: 3.3448e-05 - val_accuracy: 0.3443\n",
            "Epoch 8/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 2.4980e-05 - accuracy: 0.3491 - val_loss: 4.4732e-05 - val_accuracy: 0.3663\n",
            "Epoch 9/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 2.5383e-05 - accuracy: 0.3409 - val_loss: 2.1387e-05 - val_accuracy: 0.3496\n",
            "Epoch 10/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 1.9620e-05 - accuracy: 0.3457 - val_loss: 1.8927e-05 - val_accuracy: 0.3619\n",
            "Epoch 11/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 1.6259e-05 - accuracy: 0.3576 - val_loss: 1.3318e-05 - val_accuracy: 0.3758\n",
            "Epoch 12/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 1.5694e-05 - accuracy: 0.3718 - val_loss: 3.3687e-05 - val_accuracy: 0.3713\n",
            "Epoch 13/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 1.3576e-05 - accuracy: 0.3782 - val_loss: 1.0853e-05 - val_accuracy: 0.3876\n",
            "Epoch 14/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 1.1977e-05 - accuracy: 0.3903 - val_loss: 1.2121e-05 - val_accuracy: 0.4016\n",
            "Epoch 15/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 9.7434e-06 - accuracy: 0.4021 - val_loss: 8.7202e-06 - val_accuracy: 0.4053\n",
            "Epoch 16/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 9.5745e-06 - accuracy: 0.4043 - val_loss: 8.0570e-06 - val_accuracy: 0.4125\n",
            "Epoch 17/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 8.8220e-06 - accuracy: 0.4097 - val_loss: 7.0280e-06 - val_accuracy: 0.4168\n",
            "Epoch 18/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 8.5215e-06 - accuracy: 0.4133 - val_loss: 6.5536e-06 - val_accuracy: 0.4194\n",
            "Epoch 19/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 7.6422e-06 - accuracy: 0.4189 - val_loss: 8.2799e-06 - val_accuracy: 0.4182\n",
            "Epoch 20/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 7.7925e-06 - accuracy: 0.4185 - val_loss: 5.9854e-06 - val_accuracy: 0.4217\n",
            "Epoch 21/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 6.7972e-06 - accuracy: 0.4218 - val_loss: 6.6145e-06 - val_accuracy: 0.4229\n",
            "Epoch 22/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 5.9652e-06 - accuracy: 0.4235 - val_loss: 5.3039e-06 - val_accuracy: 0.4258\n",
            "Epoch 23/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 6.8370e-06 - accuracy: 0.4253 - val_loss: 5.9908e-06 - val_accuracy: 0.4166\n",
            "Epoch 24/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 5.4672e-06 - accuracy: 0.4279 - val_loss: 5.3996e-06 - val_accuracy: 0.4257\n",
            "Epoch 25/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 5.6434e-06 - accuracy: 0.4303 - val_loss: 5.0918e-06 - val_accuracy: 0.4232\n",
            "Epoch 26/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 6.3925e-06 - accuracy: 0.4295 - val_loss: 5.7894e-06 - val_accuracy: 0.4289\n",
            "Epoch 27/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 5.1817e-06 - accuracy: 0.4319 - val_loss: 4.6884e-06 - val_accuracy: 0.4233\n",
            "Epoch 28/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 5.0409e-06 - accuracy: 0.4330 - val_loss: 4.1093e-06 - val_accuracy: 0.4338\n",
            "Epoch 29/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 4.6995e-06 - accuracy: 0.4350 - val_loss: 4.4286e-06 - val_accuracy: 0.4359\n",
            "Epoch 30/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 4.4292e-06 - accuracy: 0.4372 - val_loss: 4.3101e-06 - val_accuracy: 0.4352\n",
            "Epoch 31/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 4.7494e-06 - accuracy: 0.4374 - val_loss: 4.4167e-06 - val_accuracy: 0.4301\n",
            "Epoch 32/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 4.2771e-06 - accuracy: 0.4389 - val_loss: 3.9922e-06 - val_accuracy: 0.4423\n",
            "Epoch 33/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 4.6603e-06 - accuracy: 0.4408 - val_loss: 3.6338e-06 - val_accuracy: 0.4441\n",
            "Epoch 34/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 4.6539e-06 - accuracy: 0.4427 - val_loss: 4.2678e-06 - val_accuracy: 0.4434\n",
            "Epoch 35/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 4.4815e-06 - accuracy: 0.4464 - val_loss: 4.3515e-06 - val_accuracy: 0.4408\n",
            "Epoch 36/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 4.3102e-06 - accuracy: 0.4459 - val_loss: 4.5612e-06 - val_accuracy: 0.4417\n",
            "Epoch 37/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 4.0103e-06 - accuracy: 0.4473 - val_loss: 4.3436e-06 - val_accuracy: 0.4494\n",
            "Epoch 38/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 3.8704e-06 - accuracy: 0.4492 - val_loss: 3.8624e-06 - val_accuracy: 0.4397\n",
            "Epoch 39/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 3.7656e-06 - accuracy: 0.4496 - val_loss: 4.2812e-06 - val_accuracy: 0.4451\n",
            "Epoch 40/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 3.9265e-06 - accuracy: 0.4504 - val_loss: 5.9967e-06 - val_accuracy: 0.4486\n",
            "Epoch 41/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 4.0541e-06 - accuracy: 0.4514 - val_loss: 3.8049e-06 - val_accuracy: 0.4451\n",
            "Epoch 42/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 3.8715e-06 - accuracy: 0.4524 - val_loss: 3.3241e-06 - val_accuracy: 0.4249\n",
            "Epoch 43/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 3.8727e-06 - accuracy: 0.4530 - val_loss: 3.3056e-06 - val_accuracy: 0.4540\n",
            "Epoch 44/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 3.6803e-06 - accuracy: 0.4534 - val_loss: 3.3571e-06 - val_accuracy: 0.4461\n",
            "Epoch 45/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 3.7409e-06 - accuracy: 0.4539 - val_loss: 3.8029e-06 - val_accuracy: 0.4411\n",
            "Epoch 46/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 3.7994e-06 - accuracy: 0.4556 - val_loss: 4.0452e-06 - val_accuracy: 0.4568\n",
            "Epoch 47/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 3.5493e-06 - accuracy: 0.4539 - val_loss: 3.3931e-06 - val_accuracy: 0.4623\n",
            "Epoch 48/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 3.8505e-06 - accuracy: 0.4548 - val_loss: 4.1675e-06 - val_accuracy: 0.4527\n",
            "Epoch 49/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 3.6964e-06 - accuracy: 0.4534 - val_loss: 4.2168e-06 - val_accuracy: 0.4563\n",
            "Epoch 50/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 3.4611e-06 - accuracy: 0.4538 - val_loss: 3.6793e-06 - val_accuracy: 0.4529\n",
            "Epoch 51/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 3.7266e-06 - accuracy: 0.4544 - val_loss: 4.2671e-06 - val_accuracy: 0.4621\n",
            "Epoch 52/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 3.5009e-06 - accuracy: 0.4539 - val_loss: 3.1237e-06 - val_accuracy: 0.4614\n",
            "Epoch 53/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 3.6193e-06 - accuracy: 0.4526 - val_loss: 3.1520e-06 - val_accuracy: 0.4593\n",
            "Epoch 54/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 3.7479e-06 - accuracy: 0.4547 - val_loss: 3.0823e-06 - val_accuracy: 0.4572\n",
            "Epoch 55/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 3.5169e-06 - accuracy: 0.4525 - val_loss: 3.4073e-06 - val_accuracy: 0.4459\n",
            "Epoch 56/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 3.3441e-06 - accuracy: 0.4546 - val_loss: 3.1654e-06 - val_accuracy: 0.4513\n",
            "Epoch 57/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 3.4243e-06 - accuracy: 0.4545 - val_loss: 3.1011e-06 - val_accuracy: 0.4494\n",
            "Epoch 58/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 3.3485e-06 - accuracy: 0.4523 - val_loss: 3.5300e-06 - val_accuracy: 0.4597\n",
            "Epoch 59/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 3.3891e-06 - accuracy: 0.4537 - val_loss: 3.4435e-06 - val_accuracy: 0.4476\n",
            "Epoch 60/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 3.3504e-06 - accuracy: 0.4535 - val_loss: 2.9382e-06 - val_accuracy: 0.4420\n",
            "Epoch 61/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 3.2162e-06 - accuracy: 0.4535 - val_loss: 3.0967e-06 - val_accuracy: 0.4544\n",
            "Epoch 62/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 3.3493e-06 - accuracy: 0.4534 - val_loss: 3.0424e-06 - val_accuracy: 0.4488\n",
            "Epoch 63/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 3.2561e-06 - accuracy: 0.4544 - val_loss: 2.9192e-06 - val_accuracy: 0.4414\n",
            "Epoch 64/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 3.3780e-06 - accuracy: 0.4537 - val_loss: 2.9953e-06 - val_accuracy: 0.4456\n",
            "Epoch 65/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 3.3374e-06 - accuracy: 0.4536 - val_loss: 2.9492e-06 - val_accuracy: 0.4495\n",
            "Epoch 66/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 3.3811e-06 - accuracy: 0.4531 - val_loss: 2.9699e-06 - val_accuracy: 0.4585\n",
            "Epoch 67/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 3.3234e-06 - accuracy: 0.4531 - val_loss: 3.4826e-06 - val_accuracy: 0.4539\n",
            "Epoch 68/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 3.1086e-06 - accuracy: 0.4537 - val_loss: 3.0950e-06 - val_accuracy: 0.4599\n",
            "Epoch 69/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 3.3822e-06 - accuracy: 0.4527 - val_loss: 4.1026e-06 - val_accuracy: 0.4529\n",
            "Epoch 70/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 3.1884e-06 - accuracy: 0.4538 - val_loss: 2.9096e-06 - val_accuracy: 0.4523\n",
            "Epoch 71/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 3.1418e-06 - accuracy: 0.4551 - val_loss: 3.0456e-06 - val_accuracy: 0.4436\n",
            "Epoch 72/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 3.0636e-06 - accuracy: 0.4535 - val_loss: 2.8169e-06 - val_accuracy: 0.4504\n",
            "Epoch 73/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 3.1497e-06 - accuracy: 0.4536 - val_loss: 3.0164e-06 - val_accuracy: 0.4412\n",
            "Epoch 74/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 3.0654e-06 - accuracy: 0.4539 - val_loss: 2.7872e-06 - val_accuracy: 0.4571\n",
            "Epoch 75/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 3.1497e-06 - accuracy: 0.4534 - val_loss: 3.0758e-06 - val_accuracy: 0.4515\n",
            "Epoch 76/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 3.1074e-06 - accuracy: 0.4560 - val_loss: 3.1677e-06 - val_accuracy: 0.4684\n",
            "Epoch 77/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 3.0214e-06 - accuracy: 0.4534 - val_loss: 3.0853e-06 - val_accuracy: 0.4634\n",
            "Epoch 78/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 3.2007e-06 - accuracy: 0.4547 - val_loss: 2.8303e-06 - val_accuracy: 0.4545\n",
            "Epoch 79/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 3.1032e-06 - accuracy: 0.4545 - val_loss: 3.0543e-06 - val_accuracy: 0.4454\n",
            "Epoch 80/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 3.0865e-06 - accuracy: 0.4544 - val_loss: 2.7547e-06 - val_accuracy: 0.4476\n",
            "Epoch 81/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 3.0850e-06 - accuracy: 0.4546 - val_loss: 2.9010e-06 - val_accuracy: 0.4511\n",
            "Epoch 82/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 3.0012e-06 - accuracy: 0.4530 - val_loss: 2.7493e-06 - val_accuracy: 0.4484\n",
            "Epoch 83/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 2.9681e-06 - accuracy: 0.4549 - val_loss: 2.8512e-06 - val_accuracy: 0.4470\n",
            "Epoch 84/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 3.1170e-06 - accuracy: 0.4539 - val_loss: 3.0007e-06 - val_accuracy: 0.4597\n",
            "Epoch 85/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 2.8767e-06 - accuracy: 0.4559 - val_loss: 2.9032e-06 - val_accuracy: 0.4627\n",
            "Epoch 86/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 2.9973e-06 - accuracy: 0.4552 - val_loss: 3.1859e-06 - val_accuracy: 0.4642\n",
            "Epoch 87/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 2.9110e-06 - accuracy: 0.4555 - val_loss: 2.8453e-06 - val_accuracy: 0.4526\n",
            "Epoch 88/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 2.9470e-06 - accuracy: 0.4556 - val_loss: 2.6147e-06 - val_accuracy: 0.4512\n",
            "Epoch 89/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 2.9597e-06 - accuracy: 0.4542 - val_loss: 2.6427e-06 - val_accuracy: 0.4416\n",
            "Epoch 90/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 2.8604e-06 - accuracy: 0.4548 - val_loss: 3.3763e-06 - val_accuracy: 0.4481\n",
            "Epoch 91/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 3.0544e-06 - accuracy: 0.4565 - val_loss: 3.3799e-06 - val_accuracy: 0.4369\n",
            "Epoch 92/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 2.9634e-06 - accuracy: 0.4525 - val_loss: 3.6428e-06 - val_accuracy: 0.4453\n",
            "Epoch 93/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 2.9005e-06 - accuracy: 0.4538 - val_loss: 3.4030e-06 - val_accuracy: 0.4464\n",
            "Epoch 94/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 2.8409e-06 - accuracy: 0.4549 - val_loss: 2.6309e-06 - val_accuracy: 0.4516\n",
            "Epoch 95/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 2.9556e-06 - accuracy: 0.4557 - val_loss: 2.6966e-06 - val_accuracy: 0.4459\n",
            "Epoch 96/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 2.7611e-06 - accuracy: 0.4540 - val_loss: 3.2951e-06 - val_accuracy: 0.4331\n",
            "Epoch 97/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 2.9225e-06 - accuracy: 0.4548 - val_loss: 2.7315e-06 - val_accuracy: 0.4579\n",
            "Epoch 98/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 2.8299e-06 - accuracy: 0.4553 - val_loss: 2.9150e-06 - val_accuracy: 0.4491\n",
            "Epoch 99/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 2.8107e-06 - accuracy: 0.4552 - val_loss: 2.7600e-06 - val_accuracy: 0.4658\n",
            "Epoch 100/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 2.7653e-06 - accuracy: 0.4538 - val_loss: 2.5561e-06 - val_accuracy: 0.4568\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gn1LFl9XF7SI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "d5f37146-820c-4828-af4c-01d7f905a5f8"
      },
      "source": [
        "encoder_layer = Model(inputs=autoencoder.inputs, outputs=autoencoder.layers[0].output)\n",
        "encoded_features = np.array(encoder_layer.predict(X_train_true_norm))\n",
        "print('Encoded feature covariance\\n', np.round(np.cov(encoded_features.T), 3))"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoded feature covariance\n",
            " [[ 0.  0. -0.]\n",
            " [ 0.  0.  0.]\n",
            " [-0.  0.  0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RiPXhfhGBMr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "415cb9e4-1680-441f-de9a-5aab9ae5ff8e"
      },
      "source": [
        "encoder = Dense(encoding_dim, activation=\"tanh\", input_shape=(input_dim,), use_bias = True,   \n",
        "                kernel_constraint=UnitNorm(axis=0) )\n",
        "#encoder = Dense(hidden_dim, activation=\"tanh\")(encoder)\n",
        "#decoder = Dense(hidden_dim, activation=\"tanh\" )(encoder)\n",
        "#decoder = DenseTied(encoding_dim, activation=\"tanh\", tied_to=encoder, use_bias = True)(decoder)\n",
        "decoder = Dense(input_dim, activation=\"tanh\", use_bias = True,\n",
        "                kernel_constraint=UnitNorm(axis=1))\n",
        "\n",
        "autoencoder = Sequential()\n",
        "autoencoder.add(encoder)\n",
        "autoencoder.add(decoder)\n",
        "#autoencoder = Model(inputs=input_layer, outputs=decoder)\n",
        "'''\n",
        "autoencoder.compile(metrics=['accuracy'],\n",
        "                    loss='mean_squared_error',\n",
        "                    optimizer='adam')\n",
        "'''\n",
        "\n",
        "autoencoder.summary()\n",
        "autoencoder.compile(metrics=['accuracy'],\n",
        "                    loss=mseTop10,\n",
        "                    optimizer='adam')\n",
        "history = autoencoder.fit(X_train_true_norm, X_train_true_norm,\n",
        "                    epochs=nb_epoch,\n",
        "                    batch_size=batch_size,\n",
        "                    shuffle=True,\n",
        "                    validation_data=(X_valid_true_norm, X_valid_true_norm),\n",
        "                    verbose=1).history\n",
        "\n"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_20 (Dense)             (None, 3)                 303       \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 100)               400       \n",
            "=================================================================\n",
            "Total params: 703\n",
            "Trainable params: 703\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 145591 samples, validate on 16212 samples\n",
            "Epoch 1/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 3.2112e-04 - accuracy: 0.0377 - val_loss: 1.0544e-04 - val_accuracy: 0.0019\n",
            "Epoch 2/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 5.8329e-05 - accuracy: 0.0812 - val_loss: 3.1731e-05 - val_accuracy: 0.1839\n",
            "Epoch 3/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.3038e-05 - accuracy: 0.2492 - val_loss: 1.5791e-05 - val_accuracy: 0.2856\n",
            "Epoch 4/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 1.2204e-05 - accuracy: 0.3164 - val_loss: 8.9596e-06 - val_accuracy: 0.3385\n",
            "Epoch 5/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 7.8009e-06 - accuracy: 0.3591 - val_loss: 6.4954e-06 - val_accuracy: 0.3715\n",
            "Epoch 6/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 6.2297e-06 - accuracy: 0.3817 - val_loss: 5.4811e-06 - val_accuracy: 0.3808\n",
            "Epoch 7/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 5.4528e-06 - accuracy: 0.4014 - val_loss: 4.8606e-06 - val_accuracy: 0.4060\n",
            "Epoch 8/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 4.8990e-06 - accuracy: 0.4176 - val_loss: 4.3830e-06 - val_accuracy: 0.4133\n",
            "Epoch 9/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 4.4110e-06 - accuracy: 0.4227 - val_loss: 3.9112e-06 - val_accuracy: 0.4188\n",
            "Epoch 10/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 3.9493e-06 - accuracy: 0.4249 - val_loss: 3.4946e-06 - val_accuracy: 0.4233\n",
            "Epoch 11/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 3.5533e-06 - accuracy: 0.4279 - val_loss: 3.1697e-06 - val_accuracy: 0.4272\n",
            "Epoch 12/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 3.2491e-06 - accuracy: 0.4316 - val_loss: 2.9454e-06 - val_accuracy: 0.4293\n",
            "Epoch 13/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 3.0577e-06 - accuracy: 0.4365 - val_loss: 2.7746e-06 - val_accuracy: 0.4354\n",
            "Epoch 14/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.9060e-06 - accuracy: 0.4426 - val_loss: 2.6719e-06 - val_accuracy: 0.4438\n",
            "Epoch 15/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.8074e-06 - accuracy: 0.4469 - val_loss: 2.5782e-06 - val_accuracy: 0.4420\n",
            "Epoch 16/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.7237e-06 - accuracy: 0.4485 - val_loss: 2.5055e-06 - val_accuracy: 0.4457\n",
            "Epoch 17/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.6537e-06 - accuracy: 0.4522 - val_loss: 2.4563e-06 - val_accuracy: 0.4498\n",
            "Epoch 18/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.6035e-06 - accuracy: 0.4529 - val_loss: 2.3999e-06 - val_accuracy: 0.4494\n",
            "Epoch 19/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.5472e-06 - accuracy: 0.4536 - val_loss: 2.3641e-06 - val_accuracy: 0.4523\n",
            "Epoch 20/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.5033e-06 - accuracy: 0.4554 - val_loss: 2.3322e-06 - val_accuracy: 0.4526\n",
            "Epoch 21/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.4678e-06 - accuracy: 0.4568 - val_loss: 2.2868e-06 - val_accuracy: 0.4526\n",
            "Epoch 22/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.4382e-06 - accuracy: 0.4578 - val_loss: 2.2605e-06 - val_accuracy: 0.4511\n",
            "Epoch 23/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.4027e-06 - accuracy: 0.4589 - val_loss: 2.2310e-06 - val_accuracy: 0.4515\n",
            "Epoch 24/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.3751e-06 - accuracy: 0.4592 - val_loss: 2.2116e-06 - val_accuracy: 0.4584\n",
            "Epoch 25/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.3479e-06 - accuracy: 0.4600 - val_loss: 2.1997e-06 - val_accuracy: 0.4572\n",
            "Epoch 26/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.3496e-06 - accuracy: 0.4593 - val_loss: 2.2140e-06 - val_accuracy: 0.4594\n",
            "Epoch 27/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 2.3175e-06 - accuracy: 0.4614 - val_loss: 2.1567e-06 - val_accuracy: 0.4614\n",
            "Epoch 28/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 2.2926e-06 - accuracy: 0.4610 - val_loss: 2.1444e-06 - val_accuracy: 0.4578\n",
            "Epoch 29/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 2.2794e-06 - accuracy: 0.4603 - val_loss: 2.1282e-06 - val_accuracy: 0.4621\n",
            "Epoch 30/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 2.2614e-06 - accuracy: 0.4614 - val_loss: 2.1089e-06 - val_accuracy: 0.4567\n",
            "Epoch 31/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 2.2573e-06 - accuracy: 0.4623 - val_loss: 2.1092e-06 - val_accuracy: 0.4524\n",
            "Epoch 32/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 2.2449e-06 - accuracy: 0.4624 - val_loss: 2.0928e-06 - val_accuracy: 0.4613\n",
            "Epoch 33/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 2.2302e-06 - accuracy: 0.4629 - val_loss: 2.0862e-06 - val_accuracy: 0.4598\n",
            "Epoch 34/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 2.2188e-06 - accuracy: 0.4606 - val_loss: 2.0797e-06 - val_accuracy: 0.4676\n",
            "Epoch 35/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.2384e-06 - accuracy: 0.4633 - val_loss: 2.0779e-06 - val_accuracy: 0.4611\n",
            "Epoch 36/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.2159e-06 - accuracy: 0.4628 - val_loss: 2.0690e-06 - val_accuracy: 0.4544\n",
            "Epoch 37/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.2164e-06 - accuracy: 0.4623 - val_loss: 2.0629e-06 - val_accuracy: 0.4591\n",
            "Epoch 38/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1902e-06 - accuracy: 0.4615 - val_loss: 2.0602e-06 - val_accuracy: 0.4559\n",
            "Epoch 39/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1874e-06 - accuracy: 0.4628 - val_loss: 2.0710e-06 - val_accuracy: 0.4643\n",
            "Epoch 40/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1957e-06 - accuracy: 0.4612 - val_loss: 2.0983e-06 - val_accuracy: 0.4425\n",
            "Epoch 41/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.2018e-06 - accuracy: 0.4616 - val_loss: 2.0508e-06 - val_accuracy: 0.4613\n",
            "Epoch 42/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1771e-06 - accuracy: 0.4621 - val_loss: 2.0547e-06 - val_accuracy: 0.4493\n",
            "Epoch 43/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1872e-06 - accuracy: 0.4620 - val_loss: 2.0450e-06 - val_accuracy: 0.4566\n",
            "Epoch 44/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.2011e-06 - accuracy: 0.4617 - val_loss: 2.1481e-06 - val_accuracy: 0.4585\n",
            "Epoch 45/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1763e-06 - accuracy: 0.4616 - val_loss: 2.0447e-06 - val_accuracy: 0.4606\n",
            "Epoch 46/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1695e-06 - accuracy: 0.4627 - val_loss: 2.0462e-06 - val_accuracy: 0.4628\n",
            "Epoch 47/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1725e-06 - accuracy: 0.4613 - val_loss: 2.0468e-06 - val_accuracy: 0.4666\n",
            "Epoch 48/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1697e-06 - accuracy: 0.4624 - val_loss: 2.0533e-06 - val_accuracy: 0.4640\n",
            "Epoch 49/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1718e-06 - accuracy: 0.4591 - val_loss: 2.0504e-06 - val_accuracy: 0.4539\n",
            "Epoch 50/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1706e-06 - accuracy: 0.4607 - val_loss: 2.0487e-06 - val_accuracy: 0.4563\n",
            "Epoch 51/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1991e-06 - accuracy: 0.4594 - val_loss: 2.0634e-06 - val_accuracy: 0.4554\n",
            "Epoch 52/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1749e-06 - accuracy: 0.4614 - val_loss: 2.0506e-06 - val_accuracy: 0.4563\n",
            "Epoch 53/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1767e-06 - accuracy: 0.4600 - val_loss: 2.0584e-06 - val_accuracy: 0.4613\n",
            "Epoch 54/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1973e-06 - accuracy: 0.4607 - val_loss: 2.0530e-06 - val_accuracy: 0.4642\n",
            "Epoch 55/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1994e-06 - accuracy: 0.4610 - val_loss: 2.0535e-06 - val_accuracy: 0.4623\n",
            "Epoch 56/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1977e-06 - accuracy: 0.4592 - val_loss: 2.0563e-06 - val_accuracy: 0.4617\n",
            "Epoch 57/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1776e-06 - accuracy: 0.4585 - val_loss: 2.0504e-06 - val_accuracy: 0.4513\n",
            "Epoch 58/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.2000e-06 - accuracy: 0.4586 - val_loss: 2.0545e-06 - val_accuracy: 0.4530\n",
            "Epoch 59/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1813e-06 - accuracy: 0.4595 - val_loss: 2.0474e-06 - val_accuracy: 0.4641\n",
            "Epoch 60/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1922e-06 - accuracy: 0.4561 - val_loss: 2.0540e-06 - val_accuracy: 0.4534\n",
            "Epoch 61/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1971e-06 - accuracy: 0.4594 - val_loss: 2.0497e-06 - val_accuracy: 0.4595\n",
            "Epoch 62/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1880e-06 - accuracy: 0.4581 - val_loss: 2.0997e-06 - val_accuracy: 0.4577\n",
            "Epoch 63/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1957e-06 - accuracy: 0.4560 - val_loss: 2.0545e-06 - val_accuracy: 0.4492\n",
            "Epoch 64/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1905e-06 - accuracy: 0.4573 - val_loss: 2.0514e-06 - val_accuracy: 0.4447\n",
            "Epoch 65/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1861e-06 - accuracy: 0.4538 - val_loss: 2.0581e-06 - val_accuracy: 0.4606\n",
            "Epoch 66/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1872e-06 - accuracy: 0.4571 - val_loss: 2.0634e-06 - val_accuracy: 0.4529\n",
            "Epoch 67/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1868e-06 - accuracy: 0.4578 - val_loss: 2.0772e-06 - val_accuracy: 0.4531\n",
            "Epoch 68/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1865e-06 - accuracy: 0.4565 - val_loss: 2.0794e-06 - val_accuracy: 0.4694\n",
            "Epoch 69/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.2112e-06 - accuracy: 0.4571 - val_loss: 2.0731e-06 - val_accuracy: 0.4506\n",
            "Epoch 70/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1945e-06 - accuracy: 0.4568 - val_loss: 2.0884e-06 - val_accuracy: 0.4431\n",
            "Epoch 71/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.2078e-06 - accuracy: 0.4542 - val_loss: 2.0705e-06 - val_accuracy: 0.4450\n",
            "Epoch 72/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.1972e-06 - accuracy: 0.4561 - val_loss: 2.0707e-06 - val_accuracy: 0.4627\n",
            "Epoch 73/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.2008e-06 - accuracy: 0.4549 - val_loss: 2.0769e-06 - val_accuracy: 0.4454\n",
            "Epoch 74/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.2069e-06 - accuracy: 0.4551 - val_loss: 2.0778e-06 - val_accuracy: 0.4621\n",
            "Epoch 75/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.2084e-06 - accuracy: 0.4573 - val_loss: 2.1057e-06 - val_accuracy: 0.4656\n",
            "Epoch 76/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.2308e-06 - accuracy: 0.4561 - val_loss: 2.0876e-06 - val_accuracy: 0.4354\n",
            "Epoch 77/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.2106e-06 - accuracy: 0.4545 - val_loss: 2.0825e-06 - val_accuracy: 0.4586\n",
            "Epoch 78/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.2211e-06 - accuracy: 0.4576 - val_loss: 2.0806e-06 - val_accuracy: 0.4482\n",
            "Epoch 79/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.2267e-06 - accuracy: 0.4527 - val_loss: 2.0786e-06 - val_accuracy: 0.4623\n",
            "Epoch 80/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.2146e-06 - accuracy: 0.4563 - val_loss: 2.0906e-06 - val_accuracy: 0.4436\n",
            "Epoch 81/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.2130e-06 - accuracy: 0.4562 - val_loss: 2.0815e-06 - val_accuracy: 0.4551\n",
            "Epoch 82/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.2141e-06 - accuracy: 0.4552 - val_loss: 2.1112e-06 - val_accuracy: 0.4491\n",
            "Epoch 83/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.2161e-06 - accuracy: 0.4566 - val_loss: 2.1139e-06 - val_accuracy: 0.4539\n",
            "Epoch 84/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.2224e-06 - accuracy: 0.4561 - val_loss: 2.0809e-06 - val_accuracy: 0.4498\n",
            "Epoch 85/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.2164e-06 - accuracy: 0.4551 - val_loss: 2.0915e-06 - val_accuracy: 0.4405\n",
            "Epoch 86/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.2263e-06 - accuracy: 0.4557 - val_loss: 2.0881e-06 - val_accuracy: 0.4575\n",
            "Epoch 87/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.2231e-06 - accuracy: 0.4514 - val_loss: 2.1001e-06 - val_accuracy: 0.4611\n",
            "Epoch 88/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.2256e-06 - accuracy: 0.4561 - val_loss: 2.0978e-06 - val_accuracy: 0.4529\n",
            "Epoch 89/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 2.2234e-06 - accuracy: 0.4563 - val_loss: 2.0864e-06 - val_accuracy: 0.4418\n",
            "Epoch 90/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 2.2160e-06 - accuracy: 0.4562 - val_loss: 2.0821e-06 - val_accuracy: 0.4603\n",
            "Epoch 91/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.2197e-06 - accuracy: 0.4578 - val_loss: 2.0971e-06 - val_accuracy: 0.4621\n",
            "Epoch 92/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 2.2192e-06 - accuracy: 0.4564 - val_loss: 2.0768e-06 - val_accuracy: 0.4551\n",
            "Epoch 93/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 2.2267e-06 - accuracy: 0.4567 - val_loss: 2.0870e-06 - val_accuracy: 0.4414\n",
            "Epoch 94/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 2.2461e-06 - accuracy: 0.4558 - val_loss: 2.1838e-06 - val_accuracy: 0.4557\n",
            "Epoch 95/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 2.2149e-06 - accuracy: 0.4571 - val_loss: 2.0836e-06 - val_accuracy: 0.4483\n",
            "Epoch 96/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 2.2150e-06 - accuracy: 0.4551 - val_loss: 2.0812e-06 - val_accuracy: 0.4429\n",
            "Epoch 97/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 2.2144e-06 - accuracy: 0.4556 - val_loss: 2.0855e-06 - val_accuracy: 0.4443\n",
            "Epoch 98/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.2233e-06 - accuracy: 0.4585 - val_loss: 2.0930e-06 - val_accuracy: 0.4572\n",
            "Epoch 99/100\n",
            "145591/145591 [==============================] - 1s 9us/step - loss: 2.2374e-06 - accuracy: 0.4561 - val_loss: 2.0884e-06 - val_accuracy: 0.4521\n",
            "Epoch 100/100\n",
            "145591/145591 [==============================] - 1s 8us/step - loss: 2.2208e-06 - accuracy: 0.4547 - val_loss: 2.0874e-06 - val_accuracy: 0.4566\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CoKuwh2uG09E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "2d1e5303-0ce8-438e-8589-27e680bc1db7"
      },
      "source": [
        "w_encoder = np.round(autoencoder.layers[0].get_weights()[0], 2).T  # W in Figure 3.\n",
        "w_decoder = np.round(autoencoder.layers[1].get_weights()[0], 2)  # W' in Figure 3.\n",
        "print('Encoder weights norm, \\n', np.round(np.sum(w_encoder ** 2, axis = 1),3))\n",
        "print('Decoder weights norm, \\n', np.round(np.sum(w_decoder ** 2, axis = 1),3))"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder weights norm, \n",
            " [1.    1.002 0.999]\n",
            "Decoder weights norm, \n",
            " [1.006 0.998 0.995]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5uKWC5TH1cj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}